{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FER2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG, Image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score, normalized_mutual_info_score, davies_bouldin_score\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### YES ###\n",
    "df = pd.read_csv(\"fer2013.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 15 random rows from the DataFrame\n",
    "random_samples = df.sample(n=15, random_state=42)  # Set random_state for reproducibility\n",
    "random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the sampled rows to display the images\n",
    "for index, row in random_samples.iterrows():\n",
    "    # Convert the pixel string into a NumPy array and reshape it\n",
    "    pixels_array = np.array(list(map(int, row[\"pixels\"].split())), dtype=np.uint8).reshape(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid for 15 images (3 rows x 5 columns)\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axes = axes.flatten()  # Flatten the grid to easily iterate\n",
    "\n",
    "# Loop through the sampled rows and display the images\n",
    "for ax, (_, row) in zip(axes, random_samples.iterrows()):\n",
    "    # Convert the pixel string into a NumPy array and reshape it\n",
    "    pixels_array = np.array(list(map(int, row[\"pixels\"].split())), dtype=np.uint8).reshape(48, 48)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(pixels_array, cmap=\"gray\")\n",
    "    # Add a title with relevant information\n",
    "    ax.set_title(f\"{row['Usage']}[{row.name}] = {row['emotion']}\")\n",
    "    ax.axis('off')  # Turn off axis for a cleaner look\n",
    "\n",
    "# Adjust layout to avoid overlapping titles\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets based on 'Usage' column\n",
    "train_fer2013 = df[df.Usage == \"Training\"]\n",
    "test_fer2013 = df[df.Usage != \"Training\"]  # Assuming all non-training rows are for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert 'pixels' column to numerical arrays\n",
    "def convert_pixels(pixels_str):\n",
    "    return np.array([int(pixel) for pixel in pixels_str.split()], dtype=np.uint8)\n",
    "\n",
    "# Apply conversion\n",
    "train_fer2013_pixels = np.vstack(train_fer2013[\"pixels\"].apply(convert_pixels).values)\n",
    "test_fer2013_pixels = np.vstack(test_fer2013[\"pixels\"].apply(convert_pixels).values)\n",
    "\n",
    "# Step 2: Reshape to flatten into 1D vectors (2304 features)\n",
    "x_train_fer2013 = train_fer2013_pixels.reshape(-1, 48 * 48)  # Shape: (28   709, 2304)\n",
    "x_test_fer2013 = test_fer2013_pixels.reshape(-1, 48 * 48)    # Shape: (7178, 2304)\n",
    "\n",
    "# Step 3: Normalize the flattened data\n",
    "scaler = StandardScaler()\n",
    "x_train_fer2013_scaled = scaler.fit_transform(x_train_fer2013)\n",
    "x_test_fer2013_scaled = scaler.transform(x_test_fer2013)\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Shape of x_train_scaled:\", x_train_fer2013_scaled.shape)  # Should be (28709, 2304)\n",
    "print(\"Shape of x_test_scaled:\", x_test_fer2013_scaled.shape)    # Should be (7178, 2304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels directly as a 1D array\n",
    "y_train_fer2013 = train_fer2013[\"emotion\"].values  # Shape: (28709,)\n",
    "y_test_fer2013 = test_fer2013[\"emotion\"].values    # Shape: (7178,)\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"Shape of y_train_fer2013:\", y_train_fer2013.shape)\n",
    "print(\"Shape of y_test_fer2013:\", y_test_fer2013.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe flatten and normalized\n",
    "print(\"Shape of x_train_fer2013:\", x_train_fer2013.shape)\n",
    "print(\"Shape of x_test_fer2013:\", x_test_fer2013.shape)\n",
    "print(\"Shape of y_train_fer2013:\", y_train_fer2013.shape)\n",
    "print(\"Shape of y_test_fer2013:\", y_test_fer2013.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Supervised UMAP -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ---------- -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- PCA + UMAP for FER2013 emotions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Apply PCA to reduce dimensionality (e.g., 50 components)\n",
    "# pca = PCA(0.85)\n",
    "# x_train_pca = pca.fit_transform(x_train_fer2013)  # x_train is the normalized flattened pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Apply UMAP for Dimensionality Reduction\n",
    "# reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "\n",
    "# # Fit and transform UMAP on the training set\n",
    "# x_train_pca_umap = reducer.fit_transform(x_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Visualize the UMAP Results\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(x_train_pca_umap[:, 0], x_train_pca_umap[:, 1], c=y_train_fer2013, cmap=\"tab10\", s=5, alpha=0.8,)\n",
    "# plt.title(\"UMAP Projection of FER2013 Training Data\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.colorbar(label=\"Emotion Labels\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Calculate Silhouette Score\n",
    "# sil_score_pca_umap = silhouette_score(x_train_pca_umap, y_train_fer2013)\n",
    "# print(f\"Silhouette Score: {sil_score_pca_umap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## CHECK NOW I HAVE CHANGED EVERYTHING OF THE PREPROCESSING ###\n",
    "\n",
    "\n",
    "# Apply UMAP for dimensionality reduction (to 2D)\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# Add the UMAP results to the dataframe\n",
    "df[\"umap_x\"] = X_umap[:, 0]\n",
    "df[\"umap_y\"] = X_umap[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the results\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df[\"umap_x\"], df[\"umap_y\"], c=df[\"emotion\"], cmap=\"tab10\", s=5, alpha=0.8)\n",
    "# plt.colorbar(scatter, label=\"Emotion\")\n",
    "# plt.title(\"UMAP Projection of FER2013 Data\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lower n_neighbors\n",
    "# # Apply UMAP for dimensionality reduction (to 2D)\n",
    "# reducer = umap.UMAP(n_neighbors=5, min_dist=0.1, n_components=2, random_state=42)\n",
    "# x_umap_fer2013 = reducer.fit_transform(x_train_fer2013)\n",
    "\n",
    "# # Add the UMAP results to the dataframe\n",
    "# df[\"umap_x_5\"] = X_umap_5[:, 0]\n",
    "# df[\"umap_y_5\"] = X_umap_5[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the results\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df[\"umap_x_5\"], df[\"umap_y_5\"], c=df[\"emotion\"], cmap=\"tab10\", s=5, alpha=0.8)\n",
    "# plt.colorbar(scatter, label=\"Emotion\")\n",
    "# plt.title(\"UMAP Projection of FER2013 Data\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply UMAP for dimensionality reduction (to 2D)\n",
    "# reducer = umap.UMAP(metric='cosine', n_neighbors=5, min_dist=0.5, n_components=2, random_state=42)\n",
    "# X_umap_5_05 = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# # Add the UMAP results to the dataframe\n",
    "# df[\"umap_x_5_05\"] = X_umap_5_05[:, 0]\n",
    "# df[\"umap_y_5_05\"] = X_umap_5_05[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the results\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df[\"umap_x_5_05\"], df[\"umap_y_5_05\"], c=df[\"emotion\"], cmap=\"tab10\", s=5, alpha=0.8)\n",
    "# plt.colorbar(scatter, label=\"Emotion\")\n",
    "# plt.title(\"UMAP Projection of FER2013 Data\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply UMAP for dimensionality reduction (to 2D)\n",
    "# reducer = umap.UMAP(metric='cosine', n_neighbors=5, min_dist=0.5, n_components=2, random_state=42)\n",
    "# X_umap_cosine_5_05 = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# # Add the UMAP results to the dataframe\n",
    "# df[\"umap_x_cosine_5_05\"] = X_umap_cosine_5_05[:, 0]\n",
    "# df[\"umap_y_cosine_5_05\"] = X_umap_cosine_5_05[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the results\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df[\"umap_x_cosine_5_05\"], df[\"umap_y_cosine_5_05\"], c=df[\"emotion\"], cmap=\"tab10\", s=5, alpha=0.8)\n",
    "# plt.colorbar(scatter, label=\"Emotion\")\n",
    "# plt.title(\"UMAP Projection of FER2013 Data\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + UMAP 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply PCA to reduce dimensionality (e.g., 50 components)\n",
    "pca = PCA(0.95)\n",
    "x_train_pca = pca.fit_transform(x_train_fer2013)  # x_train is the normalized flattened pixel data\n",
    "np.save('x_train_pca.npy', x_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of UMAP runs\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters\n",
    "\n",
    "# Store UMAP projections and KMeans results\n",
    "pca_umap_projections = []\n",
    "pca_ari_scores = []\n",
    "pca_silhouette_scores = []\n",
    "\n",
    "# Run UMAP + KMeans multiple times\n",
    "for run in range(n_runs):\n",
    "    # Step 1: Run UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    pca_projection = umap_model.fit_transform(x_train_pca, y_train_fer2013)\n",
    "    pca_umap_projections.append(pca_projection)\n",
    "\n",
    "    # Step 2: Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=run)\n",
    "    predicted_labels = kmeans.fit_predict(pca_projection)\n",
    "\n",
    "    # Step 3: Evaluate KMeans clustering\n",
    "    ari = adjusted_rand_score(y_train_fer2013, predicted_labels)\n",
    "    silhouette = silhouette_score(pca_projection, predicted_labels)\n",
    "    \n",
    "    pca_ari_scores.append(ari)\n",
    "    pca_silhouette_scores.append(silhouette)\n",
    "\n",
    "# Convert to numpy arrays for easy handling\n",
    "pca_umap_projections = np.array(pca_umap_projections)\n",
    "pca_mean_projection = np.mean(pca_umap_projections, axis=0)\n",
    "pca_std_projection = np.std(pca_umap_projections, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all UMAP runs\n",
    "for i, projection in enumerate(pca_umap_projections):\n",
    "    plt.scatter(projection[:, 0], projection[:, 1], s=3, alpha=0.3, label=f\"Run {i+1}\")\n",
    "\n",
    "# Plot the mean UMAP projection\n",
    "plt.scatter(pca_mean_projection[:, 0], pca_mean_projection[:, 1], c='red', s=5, label=\"Mean Projection\")\n",
    "\n",
    "plt.title(\"PCA + Sup. UMAP Projections Across Multiple Runs\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# # Step 5: Print Evaluation Results\n",
    "# print(f\"Mean ARI: {np.mean(ari_scores):.2f}, Std ARI: {np.std(ari_scores):.2f}\")\n",
    "# print(f\"Mean Silhouette Score: {np.mean(silhouette_scores):.2f}, Std Silhouette Score: {np.std(silhouette_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean UMAP projection as input to KMeans to assign clusters\n",
    "\n",
    "#  KMeans on the Mean Projection\n",
    "kmeans_mean = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "pca_mean_projection_clusters = kmeans_mean.fit_predict(pca_mean_projection)\n",
    "\n",
    "# Step 2: Visualize All Projections and the Mean Projection with Clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Plot all UMAP runs as background points (semi-transparent)\n",
    "# for i, projection in enumerate(umap_projections):\n",
    "#     plt.scatter(projection[:, 0], projection[:, 1], s=3, alpha=0.1, color=\"gray\", label=None)\n",
    "\n",
    "# Plot the mean UMAP projection with cluster colors\n",
    "plt.scatter(\n",
    "    pca_mean_projection[:, 0],\n",
    "    pca_mean_projection[:, 1],\n",
    "    c=pca_mean_projection_clusters,\n",
    "    cmap=\"tab10\",\n",
    "    s=10,\n",
    "    alpha=0.8,\n",
    "    label=\"Mean Projection (Clustered)\"\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"PCA + UMAP + Kmeans on Mean Projection with Cluster Assignments\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Cluster Labels (KMeans)\")\n",
    "plt.show()\n",
    "\n",
    "# # Step 3: Print Evaluation Results\n",
    "# print(f\"Mean ARI: {np.mean(ari_scores):.2f}, Std ARI: {np.std(ari_scores):.2f}\")\n",
    "# print(f\"Mean Silhouette Score: {np.mean(silhouette_scores):.2f}, Std Silhouette Score: {np.std(silhouette_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sup UMAP to PCA-reduced data\n",
    "reducer_pca = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "x_train_sup_umap_pca = reducer_pca.fit_transform(x_train_pca,y_train_fer2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_train_sup_umap_pca[:, 0],\n",
    "    x_train_sup_umap_pca[:, 1],\n",
    "    c=y_train_fer2013,  # 0 for FER2013, 1 for RAF\n",
    "    cmap=\"coolwarm\",\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title(\"PCA + Supervised UMAP Projection: Dataset Identification FER2013\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label= \"Dataset FER2013\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabor + PCA + Sup UMAP 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create Gabor Kernels\n",
    "def create_gabor_kernels():\n",
    "    \"\"\"Generates a set of Gabor kernels with different orientations and frequencies.\"\"\"\n",
    "    kernels = []\n",
    "    ksize = 31  # Kernel size\n",
    "    sigma = 4.0  # Standard deviation of the Gaussian envelope\n",
    "    lambd = 10.0  # Wavelength of the sinusoidal factor\n",
    "    gamma = 0.5  # Spatial aspect ratio\n",
    "    for theta in np.arange(0, np.pi, np.pi / 4):  # 8 orientations\n",
    "        kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=0, ktype=cv2.CV_32F)\n",
    "        kernels.append(kernel)\n",
    "    return kernels\n",
    "\n",
    "# Apply Gabor Filters\n",
    "def apply_gabor_filters(images, kernels):\n",
    "    \"\"\"Applies a set of Gabor filters to a batch of images.\"\"\"\n",
    "    gabor_features = []\n",
    "    for image in images:\n",
    "        image_2d = image.reshape(48, 48)  # Reshape back to 2D (assumes 48x48 images)\n",
    "        responses = []\n",
    "        for kernel in kernels:\n",
    "            filtered = cv2.filter2D(image_2d, cv2.CV_32F, kernel)  # Apply Gabor filter\n",
    "            responses.append(filtered.flatten())  # Flatten the filtered image\n",
    "        gabor_features.append(np.concatenate(responses))  # Concatenate all filter responses\n",
    "    return np.array(gabor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Gabor kernels\n",
    "gabor_kernels = create_gabor_kernels()\n",
    "print(f\"Generated {len(gabor_kernels)} Gabor kernels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gabor filters to the training and test sets\n",
    "x_train_gabor = apply_gabor_filters(x_train_fer2013, gabor_kernels)\n",
    "x_test_gabor = apply_gabor_filters(x_test_fer2013, gabor_kernels)\n",
    "\n",
    "print(f\"Train Gabor feature shape: {x_train_gabor.shape}\")\n",
    "print(f\"Test Gabor feature shape: {x_test_gabor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_gabor = scaler.fit_transform(x_train_gabor)\n",
    "x_test_gabor = scaler.transform(x_test_gabor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply PCA to reduce dimensionality (e.g., 50 components)\n",
    "pca = PCA(0.95)\n",
    "x_train_gabor_pca = pca.fit_transform(x_train_gabor)\n",
    "np.save('x_train_pca.npy', x_train_gabor_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of UMAP runs\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters\n",
    "\n",
    "# Store UMAP projections and KMeans results\n",
    "gabor_pca_umap_projections = []\n",
    "gabor_pca_ari_scores = []\n",
    "gabor_pca_silhouette_scores = []\n",
    "\n",
    "# Run UMAP + KMeans multiple times\n",
    "for run in range(n_runs):\n",
    "    # Step 1: Run UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    gabor_pca_projection = umap_model.fit_transform(x_train_gabor_pca, y_train_fer2013)\n",
    "    gabor_pca_umap_projections.append(gabor_pca_projection)\n",
    "\n",
    "    # Step 2: Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=run)\n",
    "    predicted_labels = kmeans.fit_predict(gabor_pca_projection)\n",
    "\n",
    "    # Step 3: Evaluate KMeans clustering\n",
    "    ari = adjusted_rand_score(y_train_fer2013, predicted_labels)\n",
    "    silhouette = silhouette_score(gabor_pca_projection, predicted_labels)\n",
    "    \n",
    "    pca_ari_scores.append(ari)\n",
    "    pca_silhouette_scores.append(silhouette)\n",
    "\n",
    "# Convert to numpy arrays for easy handling\n",
    "gabor_pca_umap_projections = np.array(gabor_pca_umap_projections)\n",
    "gabor_pca_mean_projection = np.mean(gabor_pca_umap_projections, axis=0)\n",
    "gabor_pca_std_projection = np.std(gabor_pca_umap_projections, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply KMeans to the UMAP-reduced data\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "gabor_predicted_labels = kmeans.fit_predict(gabor_pca_mean_projection)\n",
    "\n",
    "# Calculate Silhouette Score\n",
    "sil_score = silhouette_score(gabor_pca_mean_projection, gabor_predicted_labels)\n",
    "print(f\"Silhouette Score (with KMeans): {sil_score:.2f}\")\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_score = davies_bouldin_score(gabor_pca_mean_projection, gabor_predicted_labels)\n",
    "print(f\"Davies-Bouldin Index (with KMeans): {db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "sil_score2 = silhouette_score(gabor_pca_mean_projection, y_train_fer2013)\n",
    "print(f\"Silhouette Score: {sil_score2:.2f}\")\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_score2 = davies_bouldin_score(gabor_pca_mean_projection, y_train_fer2013)\n",
    "print(f\"Davies-Bouldin Index: {db_score2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_student\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Extract UMAP projections for two classes (e.g., class 0 and class 1)\n",
    "class_0 = gabor_pca_mean_projection[y_train_fer2013 == 0]\n",
    "class_1 = gabor_pca_mean_projection[y_train_fer2013 == 1]\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(class_0[:, 0], class_1[:, 0])  # Compare along UMAP component 1\n",
    "print(f\"T-test between Class 0 and Class 1: t-statistic={t_stat:.2f}, p-value={p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Fit Gaussian distributions to each class\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "gaussian_params = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    class_points = gabor_pca_mean_projection[y_train_fer2013 == label]\n",
    "    mean = np.mean(class_points, axis=0)\n",
    "    cov = np.cov(class_points, rowvar=False)\n",
    "    gaussian_params[label] = multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "# Example: Compare likelihoods of a random point belonging to each class\n",
    "sample_point = gabor_pca_mean_projection[0]  # Random point\n",
    "likelihoods = {label: dist.pdf(sample_point) for label, dist in gaussian_params.items()}\n",
    "print(\"Likelihoods for Random Point:\", likelihoods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for label in np.unique(y_train_fer2013):\n",
    "    class_points = gabor_pca_mean_projection[y_train_fer2013 == label]\n",
    "    plt.scatter(class_points[:, 0], class_points[:, 1], label=f\"Class {label}\", alpha=0.7, s=5)\n",
    "\n",
    "plt.title(\"UMAP Mean Projection with True Labels\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same metrics as before but on Kmeans results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "sil_score2 = silhouette_score(gabor_pca_mean_projection, gabor_predicted_labels)\n",
    "print(f\"Silhouette Score: {sil_score2:.2f}\")\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_score2 = davies_bouldin_score(gabor_pca_mean_projection, gabor_predicted_labels)\n",
    "print(f\"Davies-Bouldin Index: {db_score2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_student\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Extract UMAP projections for two classes (e.g., class 0 and class 1)\n",
    "class_0 = gabor_pca_mean_projection[gabor_predicted_labels == 0]\n",
    "class_1 = gabor_pca_mean_projection[gabor_predicted_labels == 1]\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(class_0[:, 0], class_1[:, 0])  # Compare along UMAP component 1\n",
    "print(f\"T-test between Class 0 and Class 1: t-statistic={t_stat:.2f}, p-value={p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Fit Gaussian distributions to each class\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "gaussian_params = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    class_points = gabor_predicted_labels[y_train_fer2013 == label]\n",
    "    mean = np.mean(class_points, axis=0)\n",
    "    cov = np.cov(class_points, rowvar=False)\n",
    "    gaussian_params[label] = multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "# Example: Compare likelihoods of a random point belonging to each class\n",
    "sample_point = gabor_predicted_labels[0]  # Random point\n",
    "likelihoods = {label: dist.pdf(sample_point) for label, dist in gaussian_params.items()}\n",
    "print(\"Likelihoods for Random Point:\", likelihoods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply PCA to reduce dimensionality (e.g., 50 components)\n",
    "pca = PCA(0.95)\n",
    "x_train_pca = pca.fit_transform(x_train_fer2013)  # x_train is the normalized flattened pixel data\n",
    "np.save('x_train_pca.npy', x_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP Parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of UMAP runs\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters\n",
    "\n",
    "# Store UMAP projections and KMeans results\n",
    "pca_umap_projections = []\n",
    "pca_ari_scores = []\n",
    "pca_silhouette_scores = []\n",
    "\n",
    "# Run UMAP + KMeans multiple times\n",
    "for run in range(n_runs):\n",
    "    # Step 1: Run UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    pca_projection = umap_model.fit_transform(x_train_pca, y_train_fer2013)\n",
    "    pca_umap_projections.append(pca_projection)\n",
    "\n",
    "    # Step 2: Apply KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=run)\n",
    "    predicted_labels = kmeans.fit_predict(pca_projection)\n",
    "\n",
    "    # Step 3: Evaluate KMeans clustering\n",
    "    ari = adjusted_rand_score(y_train_fer2013, predicted_labels)\n",
    "    silhouette = silhouette_score(pca_projection, predicted_labels)\n",
    "    \n",
    "    pca_ari_scores.append(ari)\n",
    "    pca_silhouette_scores.append(silhouette)\n",
    "\n",
    "# Convert to numpy arrays for easy handling\n",
    "pca_umap_projections = np.array(pca_umap_projections)\n",
    "pca_mean_projection = np.mean(pca_umap_projections, axis=0)\n",
    "pca_std_projection = np.std(pca_umap_projections, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset as label - Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAF Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionsDataloader(object):\n",
    "    def __init__(self, image_dir, label_file):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_file = label_file\n",
    "\n",
    "    def read_images_labels(self):  \n",
    "        train_images, train_labels = [], []\n",
    "        test_images, test_labels = [], []\n",
    "\n",
    "        # Read the label file and match labels to images\n",
    "        with open(self.label_file, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 2:\n",
    "                    image_name, label = parts[0], int(parts[1])\n",
    "                    aligned_image_name = f\"{image_name.split('.')[0]}_aligned.jpg\"\n",
    "                    image_path = os.path.join(self.image_dir, aligned_image_name)\n",
    "\n",
    "                    if os.path.exists(image_path):\n",
    "                        image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "                        image = image.resize((48, 48))  # Resize to 48x48\n",
    "\n",
    "                        # Check if the label belongs to train or test set\n",
    "                        if \"train\" in image_name:\n",
    "                            train_images.append(np.array(image))\n",
    "                            train_labels.append(label)\n",
    "                        elif \"test\" in image_name:\n",
    "                            test_images.append(np.array(image))\n",
    "                            test_labels.append(label)\n",
    "                    else:\n",
    "                        print(f\"Image not found: {aligned_image_name}\")\n",
    "\n",
    "        print(f\"Loaded {len(train_images)} training images and {len(test_images)} test images.\")\n",
    "        print(f\"Loaded {len(train_labels)} training labels and {len(test_labels)} test labels.\")\n",
    "\n",
    "        return (\n",
    "            (np.array(train_images), np.array(train_labels)),\n",
    "            (np.array(test_images), np.array(test_labels))\n",
    "        )\n",
    "\n",
    "    def load_data(self):\n",
    "        return self.read_images_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "input_path = 'C:/Users/Lorenzo/OneDrive/Documents/DTU/Python/2024 Fall/MSc Thesis'\n",
    "image_dir = os.path.join(input_path, 'extracted_data/Image/aligned')\n",
    "label_file = os.path.join(input_path, 'extracted_data/EmoLabel/list_patition_label.txt')\n",
    "\n",
    "# Instantiate and load the dataset\n",
    "emotions_dataloader = EmotionsDataloader(image_dir, label_file)\n",
    "(x_train_RAF, y_train_RAF), (x_test_RAF, y_test_RAF) = emotions_dataloader.load_data()\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training set shape: {x_train_RAF.shape}, {y_train_RAF.shape}\")\n",
    "print(f\"Testing set shape: {x_test_RAF.shape}, {y_test_RAF.shape}\")\n",
    "\n",
    "# Display some random train and test images\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images) / cols) + 1\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (image, title) in enumerate(zip(images, title_texts)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        plt.title(title, fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "# Show some random train and test images\n",
    "images_to_show = []\n",
    "titles_to_show = []\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(x_train_RAF))\n",
    "    images_to_show.append(x_train_RAF[idx])\n",
    "    titles_to_show.append(f\"Train[{idx}] = {y_train_RAF[idx]}\")\n",
    "\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(0, len(x_test_RAF))\n",
    "    images_to_show.append(x_test_RAF[idx])\n",
    "    titles_to_show.append(f\"Test[{idx}] = {y_test_RAF[idx]}\")\n",
    "\n",
    "show_images(images_to_show, titles_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Training Data (RAF)\n",
    "train_raf_df = pd.DataFrame({\n",
    "    \"emotion\": y_train_RAF,\n",
    "    \"pixels\": [\" \".join(map(str, x.flatten())) for x in x_train_RAF],  # Flatten images and store as strings\n",
    "    \"Dataset\": \"RAF\",\n",
    "    \"Usage\": \"Training\"\n",
    "})\n",
    "\n",
    "# Convert Testing Data (RAF)\n",
    "test_raf_df = pd.DataFrame({\n",
    "    \"emotion\": y_test_RAF,\n",
    "    \"pixels\": [\" \".join(map(str, x.flatten())) for x in x_test_RAF],  # Flatten images and store as strings\n",
    "    \"Dataset\": \"RAF\",\n",
    "    \"Usage\": \"Testing\"\n",
    "})\n",
    "\n",
    "# Combine RAF Train and Test\n",
    "raf_combined_df = pd.concat([train_raf_df, test_raf_df], ignore_index=True)\n",
    "\n",
    "# Verify the structure of the RAF DataFrame\n",
    "print(raf_combined_df.head())\n",
    "print(\"RAF Combined Shape:\", raf_combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine RAF and FER2013 datasets\n",
    "combined_df = pd.concat([raf_combined_df, df], ignore_index=True)\n",
    "\n",
    "# Verify the combined DataFrame\n",
    "print(\"Combined Dataset Shape:\", combined_df.shape)\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining RAF & FER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'pixels' column to numerical arrays for verification\n",
    "combined_df[\"pixels\"] = combined_df[\"pixels\"].apply(lambda x: np.array(list(map(int, x.split()))))\n",
    "\n",
    "# Check the shape of the first row to confirm it is flattened\n",
    "print(\"Shape of a single image (pixels):\", combined_df[\"pixels\"].iloc[0].shape)  # Expected: (2304,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean and standard deviation of pixel values\n",
    "pixel_values = np.vstack(combined_df[\"pixels\"].values)\n",
    "print(\"Mean of pixel values:\", pixel_values.mean())\n",
    "print(\"Standard deviation of pixel values:\", pixel_values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "scaler = StandardScaler()\n",
    "normalized_pixels = scaler.fit_transform(pixel_values)  # Normalize pixel values\n",
    "\n",
    "# Update the 'pixels' column with normalized values\n",
    "combined_df[\"pixels\"] = list(normalized_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'Usage' column values to 'Testing' if they are 'PrivateTest' or 'PublicTest'\n",
    "combined_df.loc[(combined_df[\"Usage\"] == \"PrivateTest\") | (combined_df[\"Usage\"] == \"PublicTest\"), \"Usage\"] = \"Testing\"\n",
    "\n",
    "# Check if the update was successful\n",
    "print(combined_df[\"Usage\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'Dataset' column as 0 (FER2013) and 1 (RAF)\n",
    "combined_df[\"Dataset\"] = combined_df[\"Dataset\"].map({\"FER2013\": 0, \"RAF\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df[\"Dataset\"].isna().sum())  # Check for NaN values in the 'Dataset' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in Dataset column after encoding:\", combined_df[\"Dataset\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "merged_train_data = combined_df[combined_df[\"Usage\"] == \"Training\"]\n",
    "merged_test_data = combined_df[combined_df[\"Usage\"] != \"Training\"]\n",
    "\n",
    "# Extract X (pixels) and y (Dataset) for training and testing\n",
    "merged_x_train = np.vstack(merged_train_data[\"pixels\"].values)  # Convert list of arrays to 2D array\n",
    "merged_y_train = merged_train_data[\"Dataset\"].values\n",
    "\n",
    "merged_x_test = np.vstack(merged_test_data[\"pixels\"].values)  # Convert list of arrays to 2D array\n",
    "merged_y_test = merged_test_data[\"Dataset\"].values\n",
    "\n",
    "# Verify shapes\n",
    "print(\"merged_x_train shape:\", merged_x_train.shape)  # Expected: (num_train_samples, 2304)\n",
    "print(\"merged_y_train shape:\", merged_y_train.shape)  # Expected: (num_train_samples,)\n",
    "print(\"merged_x_test shape:\", merged_x_test.shape)    # Expected: (num_test_samples, 2304)\n",
    "print(\"merged_y_test shape:\", merged_y_test.shape)    # Expected: (num_test_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAF vs FER Sup UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighhours = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 50\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "raf_fer_sup_umap_train_50_01 = []\n",
    "raf_fer_sup_umap_test_50_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running supervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(merged_x_train, merged_y_train)\n",
    "    raf_fer_sup_umap_train_50_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(merged_x_test)\n",
    "    raf_fer_sup_umap_test_50_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "raf_fer_sup_umap_train_50_01 = np.array(raf_fer_sup_umap_train_50_01)\n",
    "raf_fer_sup_umap_test_50_01 = np.array(raf_fer_sup_umap_test_50_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "raf_fer_mean_sup_umap_projection_train_50_01 = np.mean(raf_fer_sup_umap_train_50_01, axis=0)\n",
    "raf_fer_std_sup_umap_projection_train_50_01 = np.std(raf_fer_sup_umap_train_50_01, axis=0)\n",
    "\n",
    "raf_fer_mean_sup_umap_projection_test_50_01 = np.mean(raf_fer_sup_umap_test_50_01, axis=0)\n",
    "raf_fer_std_sup_umap_projection_test_50_01 = np.std(raf_fer_sup_umap_test_50_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('raf_fer_sup_umap_train_50_01.npy', raf_fer_sup_umap_train_50_01)\n",
    "np.save('raf_fer_mean_sup_umap_projection_train_50_01.npy', raf_fer_mean_sup_umap_projection_train_50_01)\n",
    "np.save('raf_fer_std_sup_umap_projection_train_50_01.npy', raf_fer_std_sup_umap_projection_train_50_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('raf_fer_sup_umap_test_50_01.npy', raf_fer_sup_umap_test_50_01)\n",
    "np.save('raf_fer_mean_sup_umap_projection_test_50_01.npy', raf_fer_mean_sup_umap_projection_test_50_01)\n",
    "np.save('raf_fer_std_sup_umap_projection_test_50_01.npy', raf_fer_std_sup_umap_projection_test_50_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"supervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define a custom colormap with green and blue\n",
    "custom_cmap = ListedColormap([\"lightgreen\", \"pink\"])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    raf_fer_mean_sup_umap_projection_train_50_01[:, 0],\n",
    "    raf_fer_mean_sup_umap_projection_train_50_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"n_neighbours=50 Supervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "cbar.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "cbar.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_raf_fer_umap_sup_50_01 = adjusted_rand_score(merged_y_test, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_sup_umap_projection_train_50_01, merged_y_train).predict(raf_fer_mean_sup_umap_projection_test_50_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_raf_fer_umap_sup_50_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_raf_fer_umap_sup_50_01 = silhouette_score(raf_fer_mean_sup_umap_projection_test_50_01, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_sup_umap_projection_train_50_01, merged_y_train).predict(raf_fer_mean_sup_umap_projection_test_50_01))\n",
    "print(f\"Silhouette Score: {silhouette_raf_fer_umap_sup_50_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(merged_y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(raf_fer_mean_sup_umap_projection_train_50_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "raf_fer_sup_umap_projection_50_01_db_score = davies_bouldin_score(\n",
    "    raf_fer_mean_sup_umap_projection_train_50_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {raf_fer_sup_umap_projection_50_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_neighbours = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "raf_fer_sup_umap_train_10_01= np.load('raf_fer_sup_umap_train_10_01.npy')\n",
    "raf_fer_mean_sup_umap_projection_train_10_01= np.load('raf_fer_mean_sup_umap_projection_train_10_01.npy')\n",
    "raf_fer_std_sup_umap_projection_train_10_01= np.load('raf_fer_std_sup_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "raf_fer_sup_umap_test_10_01= np.load('raf_fer_sup_umap_test_10_01.npy')\n",
    "raf_fer_mean_sup_umap_projection_test_10_01= np.load('raf_fer_mean_sup_umap_projection_test_10_01.npy')\n",
    "raf_fer_std_sup_umap_projection_test_10_01= np.load('raf_fer_std_sup_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "raf_fer_sup_umap_train_10_01 = []\n",
    "raf_fer_sup_umap_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running Supervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(merged_x_train, merged_y_train)\n",
    "    raf_fer_sup_umap_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(merged_x_test)\n",
    "    raf_fer_sup_umap_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "raf_fer_sup_umap_train_10_01 = np.array(raf_fer_sup_umap_train_10_01)\n",
    "raf_fer_sup_umap_test_10_01 = np.array(raf_fer_sup_umap_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "raf_fer_mean_sup_umap_projection_train_10_01 = np.mean(raf_fer_sup_umap_train_10_01, axis=0)\n",
    "raf_fer_std_sup_umap_projection_train_10_01 = np.std(raf_fer_sup_umap_train_10_01, axis=0)\n",
    "\n",
    "raf_fer_mean_sup_umap_projection_test_10_01 = np.mean(raf_fer_sup_umap_test_10_01, axis=0)\n",
    "raf_fer_std_sup_umap_projection_test_10_01 = np.std(raf_fer_sup_umap_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('raf_fer_sup_umap_train_10_01.npy', raf_fer_sup_umap_train_10_01)\n",
    "np.save('raf_fer_mean_sup_umap_projection_train_10_01.npy', raf_fer_mean_sup_umap_projection_train_10_01)\n",
    "np.save('raf_fer_std_sup_umap_projection_train_10_01.npy', raf_fer_std_sup_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('raf_fer_sup_umap_test_10_01.npy', raf_fer_sup_umap_test_10_01)\n",
    "np.save('raf_fer_mean_sup_umap_projection_test_10_01.npy', raf_fer_mean_sup_umap_projection_test_10_01)\n",
    "np.save('raf_fer_std_sup_umap_projection_test_10_01.npy', raf_fer_std_sup_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"Supervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define a custom colormap with green and blue\n",
    "custom_cmap = ListedColormap([\"lightgreen\", \"blue\"])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    raf_fer_mean_sup_umap_projection_train_10_01[:, 0],\n",
    "    raf_fer_mean_sup_umap_projection_train_10_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Supervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "cbar.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "cbar.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_raf_fer_umap_sup_10_01 = adjusted_rand_score(merged_y_test, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_sup_umap_projection_train_10_01, merged_y_train).predict(raf_fer_mean_sup_umap_projection_test_10_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_raf_fer_umap_sup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_raf_fer_umap_sup_10_01 = silhouette_score(raf_fer_mean_sup_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_sup_umap_projection_train_10_01, merged_y_train).predict(raf_fer_mean_sup_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_raf_fer_umap_sup_10_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(merged_y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(raf_fer_mean_sup_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "raf_fer_sup_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    raf_fer_mean_sup_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {raf_fer_sup_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAF vs FER Unsup UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 50\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "raf_fer_unsup_umap_train_50_01 = []\n",
    "raf_fer_unsup_umap_test_50_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running unsupervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(merged_x_train)\n",
    "    raf_fer_unsup_umap_train_50_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(merged_x_test)\n",
    "    raf_fer_unsup_umap_test_50_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "raf_fer_unsup_umap_train_50_01 = np.array(raf_fer_unsup_umap_train_50_01)\n",
    "raf_fer_unsup_umap_test_50_01 = np.array(raf_fer_unsup_umap_test_50_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "raf_fer_mean_unsup_umap_projection_train_50_01 = np.mean(raf_fer_unsup_umap_train_50_01, axis=0)\n",
    "raf_fer_std_unsup_umap_projection_train_50_01 = np.std(raf_fer_unsup_umap_train_50_01, axis=0)\n",
    "\n",
    "raf_fer_mean_unsup_umap_projection_test_50_01 = np.mean(raf_fer_unsup_umap_test_50_01, axis=0)\n",
    "raf_fer_std_unsup_umap_projection_test_50_01 = np.std(raf_fer_unsup_umap_test_50_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('raf_fer_unsup_umap_train_50_01.npy', raf_fer_unsup_umap_train_50_01)\n",
    "np.save('raf_fer_mean_unsup_umap_projection_train_50_01.npy', raf_fer_mean_unsup_umap_projection_train_50_01)\n",
    "np.save('raf_fer_std_unsup_umap_projection_train_50_01.npy', raf_fer_std_unsup_umap_projection_train_50_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('raf_fer_unsup_umap_test_50_01.npy', raf_fer_unsup_umap_test_50_01)\n",
    "np.save('raf_fer_mean_unsup_umap_projection_test_50_01.npy', raf_fer_mean_unsup_umap_projection_test_50_01)\n",
    "np.save('raf_fer_std_unsup_umap_projection_test_50_01.npy', raf_fer_std_unsup_umap_projection_test_50_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"unsupervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define a custom colormap with green and blue\n",
    "custom_cmap = ListedColormap([\"lightgreen\", \"pink\"])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    raf_fer_mean_unsup_umap_projection_train_50_01[:, 0],\n",
    "    raf_fer_mean_unsup_umap_projection_train_50_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"n_neighbours=50 Unsupervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "cbar.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "cbar.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_raf_fer_umap_unsup_50_01 = adjusted_rand_score(merged_y_test, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_unsup_umap_projection_train_50_01, merged_y_train).predict(raf_fer_mean_unsup_umap_projection_test_50_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_raf_fer_umap_unsup_50_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_raf_fer_umap_unsup_50_01 = silhouette_score(raf_fer_mean_unsup_umap_projection_test_50_01, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_unsup_umap_projection_train_50_01, merged_y_train).predict(raf_fer_mean_unsup_umap_projection_test_50_01))\n",
    "print(f\"Silhouette Score: {silhouette_raf_fer_umap_unsup_50_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(merged_y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(raf_fer_mean_unsup_umap_projection_train_50_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "raf_fer_unsup_umap_projection_50_01_db_score = davies_bouldin_score(\n",
    "    raf_fer_mean_unsup_umap_projection_train_50_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {raf_fer_unsup_umap_projection_50_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_neighbours= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "raf_fer_unsup_umap_train_10_01= np.load('raf_fer_unsup_umap_train_10_01.npy')\n",
    "raf_fer_mean_unsup_umap_projection_train_10_01= np.load('raf_fer_mean_unsup_umap_projection_train_10_01.npy')\n",
    "raf_fer_std_unsup_umap_projection_train_10_01= np.load('raf_fer_std_unsup_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "raf_fer_unsup_umap_test_10_01= np.load('raf_fer_unsup_umap_test_10_01.npy')\n",
    "raf_fer_mean_unsup_umap_projection_test_10_01= np.load('raf_fer_mean_unsup_umap_projection_test_10_01.npy')\n",
    "raf_fer_std_unsup_umap_projection_test_10_01= np.load('raf_fer_std_unsup_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "raf_fer_unsup_umap_train_10_01 = []\n",
    "raf_fer_unsup_umap_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running unsupervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(merged_x_train)\n",
    "    raf_fer_unsup_umap_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(merged_x_test)\n",
    "    raf_fer_unsup_umap_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "raf_fer_unsup_umap_train_10_01 = np.array(raf_fer_unsup_umap_train_10_01)\n",
    "raf_fer_unsup_umap_test_10_01 = np.array(raf_fer_unsup_umap_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "raf_fer_mean_unsup_umap_projection_train_10_01 = np.mean(raf_fer_unsup_umap_train_10_01, axis=0)\n",
    "raf_fer_std_unsup_umap_projection_train_10_01 = np.std(raf_fer_unsup_umap_train_10_01, axis=0)\n",
    "\n",
    "raf_fer_mean_unsup_umap_projection_test_10_01 = np.mean(raf_fer_unsup_umap_test_10_01, axis=0)\n",
    "raf_fer_std_unsup_umap_projection_test_10_01 = np.std(raf_fer_unsup_umap_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('raf_fer_unsup_umap_train_10_01.npy', raf_fer_unsup_umap_train_10_01)\n",
    "np.save('raf_fer_mean_unsup_umap_projection_train_10_01.npy', raf_fer_mean_unsup_umap_projection_train_10_01)\n",
    "np.save('raf_fer_std_unsup_umap_projection_train_10_01.npy', raf_fer_std_unsup_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('raf_fer_unsup_umap_test_10_01.npy', raf_fer_unsup_umap_test_10_01)\n",
    "np.save('raf_fer_mean_unsup_umap_projection_test_10_01.npy', raf_fer_mean_unsup_umap_projection_test_10_01)\n",
    "np.save('raf_fer_std_unsup_umap_projection_test_10_01.npy', raf_fer_std_unsup_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"unsupervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define a custom colormap with green and blue\n",
    "custom_cmap = ListedColormap([\"lightgreen\", \"blue\"])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    raf_fer_mean_unsup_umap_projection_train_10_01[:, 0],\n",
    "    raf_fer_mean_unsup_umap_projection_train_10_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Unsupervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "cbar.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "cbar.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_raf_fer_umap_unsup_10_01 = adjusted_rand_score(merged_y_test, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_unsup_umap_projection_train_10_01, merged_y_train).predict(raf_fer_mean_unsup_umap_projection_test_10_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_raf_fer_umap_unsup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_raf_fer_umap_unsup_10_01 = silhouette_score(raf_fer_mean_unsup_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(raf_fer_mean_unsup_umap_projection_train_10_01, merged_y_train).predict(raf_fer_mean_unsup_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_raf_fer_umap_unsup_10_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(merged_y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(raf_fer_mean_unsup_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "raf_fer_unsup_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    raf_fer_mean_unsup_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {raf_fer_unsup_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom colormap with green and blue\n",
    "custom_cmap = ListedColormap([\"lightgreen\", \"blue\"])\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot the unsupervised UMAP\n",
    "scatter1 = axes[0].scatter(\n",
    "    raf_fer_mean_unsup_umap_projection_train_10_01[:, 0],\n",
    "    raf_fer_mean_unsup_umap_projection_train_10_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "axes[0].set_title(\"Unsupervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "axes[0].set_xlabel(\"UMAP Component 1\")\n",
    "axes[0].set_ylabel(\"UMAP Component 2\")\n",
    "# cbar1 = fig.colorbar(scatter1, ax=axes[0], orientation=\"vertical\")\n",
    "# cbar1.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "# cbar1.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "# cbar1.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "# Plot the supervised UMAP\n",
    "scatter2 = axes[1].scatter(\n",
    "    raf_fer_mean_sup_umap_projection_train_10_01[:, 0],\n",
    "    raf_fer_mean_sup_umap_projection_train_10_01[:, 1],\n",
    "    c=merged_y_train,\n",
    "    cmap=custom_cmap,\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "axes[1].set_title(\"Supervised UMAP Projection of RAFDB-FER2013 Merged Training Data (10 Runs)\")\n",
    "axes[1].set_xlabel(\"UMAP Component 1\")\n",
    "axes[1].set_ylabel(\"UMAP Component 2\")\n",
    "cbar2 = fig.colorbar(scatter2, ax=axes[1], orientation=\"vertical\")\n",
    "cbar2.set_ticks([0, 1])  # Ensure ticks align with both labels\n",
    "cbar2.set_ticklabels([\"Original source 0 - (FER2013)\", \"Original source 1 - (RAF-DB)\"])  # Customize labels\n",
    "cbar2.set_label(\"Image Original Source Labels\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# n_neighbors = 10\n",
    "# min_dist = 0.1\n",
    "# n_components = 2\n",
    "# n_runs = 10  # Number of runs\n",
    "\n",
    "# # Store UMAP projections for each run\n",
    "# RAF_FER_sup_umap_projections_10_01 = []\n",
    "\n",
    "# # Run UMAP multiple times\n",
    "# for run in range(n_runs):\n",
    "#     # Create UMAP model\n",
    "#     umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components,random_state=None)\n",
    "    \n",
    "#     # Fit and transform the data\n",
    "#     RAF_FER_projection = umap_model.fit_transform(x_train,y_train)\n",
    "    \n",
    "#     # Store the projection\n",
    "#     RAF_FER_sup_umap_projections_10_01.append(RAF_FER_projection)\n",
    "\n",
    "# # Convert the list of projections to a numpy array\n",
    "# RAF_FER_sup_umap_projections_10_01 = np.array(RAF_FER_sup_umap_projections_10_01)\n",
    "\n",
    "# # Calculate mean and standard deviation of projections across runs\n",
    "# RAF_FER_mean_sup_umap_projection_10_01 = np.mean(RAF_FER_sup_umap_projections_10_01, axis=0)\n",
    "# RAF_FER_std_sup_umap_projection_10_01 = np.std(RAF_FER_sup_umap_projections_10_01, axis=0)\n",
    "\n",
    "# # Save the projections, mean, and standard deviation\n",
    "# np.save('RAF_FER_sup_umap_projections_10_01.npy', RAF_FER_sup_umap_projections_10_01)\n",
    "# np.save('RAF_FER_mean_sup_projection_10_01_35.npy', RAF_FER_mean_sup_umap_projection_10_01)\n",
    "# np.save('RAF_FER_std_sup_projection_10_01_35.npy', RAF_FER_std_sup_umap_projection_10_01)\n",
    "\n",
    "# # Output confirmation\n",
    "# print(\"UMAP projections, mean, and standard deviation have been saved with identifiers '_10_01'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the UMAP results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(RAF_FER_mean_sup_umap_projection_10_01[:, 0], RAF_FER_mean_sup_umap_projection_10_01[:, 1], c=y_train, cmap=\"coolwarm\", s=5, alpha=0.8)\n",
    "plt.title(\"Sup. UMAP Projection: Dataset Identification (RAF vs FER2013)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Dataset (0=FER2013, 1=RAF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "RAF_FER_sil_score = silhouette_score(RAF_FER_mean_sup_umap_projection_10_01, y_train)\n",
    "print(f\"Silhouette Score: {RAF_FER_sil_score:.2f}\")\n",
    "# Calculate Davies-Bouldin Index\n",
    "RAF_FER_db_score = davies_bouldin_score(RAF_FER_mean_sup_umap_projection_10_01, y_train)\n",
    "print(f\"Davies-Bouldin Index: {RAF_FER_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_student\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Extract UMAP projections for two classes (e.g., class 0 and class 1)\n",
    "class_0 = RAF_FER_mean_sup_umap_projection_10_01[y_train == 0]\n",
    "class_1 = RAF_FER_mean_sup_umap_projection_10_01[y_train == 1]\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(class_0[:, 0], class_1[:, 0])  # Compare along UMAP component 1\n",
    "print(f\"T-test between Class 0 and Class 1: t-statistic={t_stat:.2f}, p-value={p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT RUN YET ##\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Fit Gaussian distributions to each class\n",
    "unique_labels = np.unique(y_train)\n",
    "gaussian_params = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    class_points = gabor_predicted_labels[y_train == label]\n",
    "    mean = np.mean(class_points, axis=0)\n",
    "    cov = np.cov(class_points, rowvar=False)\n",
    "    gaussian_params[label] = multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "# Example: Compare likelihoods of a random point belonging to each class\n",
    "sample_point = gabor_predicted_labels[0]  # Random point\n",
    "likelihoods = {label: dist.pdf(sample_point) for label, dist in gaussian_params.items()}\n",
    "print(\"Likelihoods for Random Point:\", likelihoods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply KMeans to the UMAP-reduced data\n",
    "n_clusters = len(np.unique(y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "predicted_labels = kmeans.fit_predict(x_train_sup_umap)\n",
    "\n",
    "# Calculate Silhouette Score\n",
    "sil_score = silhouette_score(x_train_sup_umap, predicted_labels)\n",
    "print(f\"Silhouette Score (with KMeans): {sil_score:.2f}\")\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_score = davies_bouldin_score(x_train_sup_umap, predicted_labels)\n",
    "print(f\"Davies-Bouldin Index (with KMeans): {db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "ari = adjusted_rand_score(y_train, predicted_labels)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari:.2f}\")\n",
    "\n",
    "nmi = normalized_mutual_info_score(y_train, predicted_labels)\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Unsupervised UMAP only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run\n",
    "RAF_FER_unsup_umap_projections_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=None)\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    RAF_FER_unsup_map_projection = umap_model.fit_transform(x_train)\n",
    "    \n",
    "    # Store the projection\n",
    "    RAF_FER_unsup_umap_projections_10_01.append(RAF_FER_unsup_map_projection)\n",
    "\n",
    "# Convert the list of projections to a numpy array\n",
    "RAF_FER_unsup_umap_projections_10_01 = np.array(RAF_FER_unsup_umap_projections_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs\n",
    "RAF_FER_mean_unsup_umap_projection_10_01 = np.mean(RAF_FER_unsup_umap_projections_10_01, axis=0)\n",
    "RAF_FER_std_unsup_umap_projection_10_01 = np.std(RAF_FER_unsup_umap_projections_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation\n",
    "np.save('RAF_FER_unsup_umap_projections_10_01.npy', RAF_FER_unsup_umap_projections_10_01)\n",
    "np.save('RAF_FER_mean_unsup_projection_10_01_35.npy', RAF_FER_mean_unsup_umap_projection_10_01)\n",
    "np.save('RAF_FER_std_unsup_projection_10_01_35.npy', RAF_FER_std_unsup_umap_projection_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections, mean, and standard deviation have been saved with identifiers '_10_01'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mask for FER2013 and RAF\n",
    "mask_fer = (y_train == 0)\n",
    "mask_raf = (y_train == 1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot FER2013\n",
    "plt.scatter(\n",
    "    RAF_FER_mean_unsup_umap_projection_10_01[mask_fer, 0],\n",
    "    RAF_FER_mean_unsup_umap_projection_10_01[mask_fer, 1],\n",
    "    color='blue', label=\"FER2013\", marker='o', s=10, alpha=0.7\n",
    ")\n",
    "\n",
    "# Plot RAF\n",
    "plt.scatter(\n",
    "    RAF_FER_mean_unsup_umap_projection_10_01[mask_raf, 0],\n",
    "    RAF_FER_mean_unsup_umap_projection_10_01[mask_raf, 1],\n",
    "    color='red', label=\"RAF\", marker='^', s=10, alpha=0.7\n",
    ")\n",
    "\n",
    "plt.title(\"Unsup. UMAP Mean Projection: Dataset Identification (RAF vs FER2013)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "RAF_FER_unsup_sil_score = silhouette_score(RAF_FER_mean_unsup_umap_projection_10_01, y_train)\n",
    "print(f\"Silhouette Score: {RAF_FER_unsup_sil_score:.2f}\")\n",
    "# Calculate Davies-Bouldin Index\n",
    "RAF_FER_unsup_db_score = davies_bouldin_score(RAF_FER_mean_unsup_umap_projection_10_01, y_train)\n",
    "print(f\"Davies-Bouldin Index: {RAF_FER_unsup_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans to the UMAP-reduced data\n",
    "n_clusters = len(np.unique(y_train))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "RAF_FER_mean_unsup_predicted_labels = kmeans.fit_predict(RAF_FER_mean_unsup_umap_projection_10_01)\n",
    "\n",
    "ari = adjusted_rand_score(y_train, RAF_FER_mean_unsup_predicted_labels)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari:.2f}\")\n",
    "\n",
    "nmi = normalized_mutual_info_score(y_train, RAF_FER_mean_unsup_predicted_labels)\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the UMAP results for 1 run\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(x_train_umap2[:, 0], x_train_umap2[:, 1], c=y_train, cmap=\"coolwarm\", s=5, alpha=0.8)\n",
    "plt.title(\"UMAP Projection: Dataset Identification (RAF vs FER2013)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Dataset (0=FER2013, 1=RAF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette score\n",
    "sil_score = silhouette_score(x_train_umap, y_train)\n",
    "sil_score2 = silhouette_score(x_train_umap2, y_train)\n",
    "print(\"Silhouette Score:\", sil_score, sil_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA + UMAP**\tFaster; simple to implement; removes noise.\tMay lose critical image features.\n",
    "\n",
    "**ResNet50 + UMAP** Leverages pretrained features for better results.\tSlower; requires more memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP FER2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised UMAP Standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_sup_umap_projections_train_10_01= np.load('fer_sup_umap_projections_train_10_01.npy')\n",
    "fer_mean_sup_umap_projection_train_10_01= np.load('fer_mean_sup_umap_projection_train_10_01.npy')\n",
    "fer_std_sup_umap_projection_train_10_01= np.load('fer_std_sup_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_sup_umap_projections_test_10_01= np.load('fer_sup_umap_projections_test_10_01.npy')\n",
    "fer_mean_sup_umap_projection_test_10_01= np.load('fer_mean_sup_umap_projection_test_10_01.npy')\n",
    "fer_std_sup_umap_projection_test_10_01= np.load('fer_std_sup_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "fer_sup_umap_projections_train_10_01 = []\n",
    "fer_sup_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running Supervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(x_train_fer2013, y_train_fer2013)\n",
    "    fer_sup_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer2013)\n",
    "    fer_sup_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_sup_umap_projections_train_10_01 = np.array(fer_sup_umap_projections_train_10_01)\n",
    "fer_sup_umap_projections_test_10_01 = np.array(fer_sup_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_sup_umap_projection_train_10_01 = np.mean(fer_sup_umap_projections_train_10_01, axis=0)\n",
    "fer_std_sup_umap_projection_train_10_01 = np.std(fer_sup_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_sup_umap_projection_test_10_01 = np.mean(fer_sup_umap_projections_test_10_01, axis=0)\n",
    "fer_std_sup_umap_projection_test_10_01 = np.std(fer_sup_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_sup_umap_projections_train_10_01.npy', fer_sup_umap_projections_train_10_01)\n",
    "np.save('fer_mean_sup_umap_projection_train_10_01.npy', fer_mean_sup_umap_projection_train_10_01)\n",
    "np.save('fer_std_sup_umap_projection_train_10_01.npy', fer_std_sup_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_sup_umap_projections_test_10_01.npy', fer_sup_umap_projections_test_10_01)\n",
    "np.save('fer_mean_sup_umap_projection_test_10_01.npy', fer_mean_sup_umap_projection_test_10_01)\n",
    "np.save('fer_std_sup_umap_projection_test_10_01.npy', fer_std_sup_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"Supervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the projections, mean, and standard deviation for the test set\n",
    "fer_sup_umap_projections_train_10_01= np.load('fer_sup_umap_projections_train_10_01.npy')\n",
    "fer_mean_sup_umap_projection_train_10_01= np.load('fer_mean_sup_umap_projection_train_10_01.npy')\n",
    "fer_std_sup_umap_projection_train_10_01= np.load('fer_std_sup_umap_projection_train_10_01.npy')\n",
    "\n",
    "# Load the projections, mean, and standard deviation for the test set\n",
    "fer_sup_umap_projections_test_10_01= np.load('fer_sup_umap_projections_test_10_01.npy')\n",
    "fer_mean_sup_umap_projection_test_10_01= np.load('fer_mean_sup_umap_projection_test_10_01.npy')\n",
    "fer_std_sup_umap_projection_test_10_01= np.load('fer_std_sup_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(fer_mean_sup_umap_projection_train_10_01[:, 0], fer_mean_sup_umap_projection_train_10_01[:, 1], c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Supervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_umap_sup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_umap_projection_test_10_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_fer_umap_sup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_umap_sup_10_01 = silhouette_score(fer_mean_sup_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_umap_sup_10_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_sup_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_sup_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_sup_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_sup_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate Silhouette Score\n",
    "# FER_sup_sil_score = silhouette_score(fer_mean_sup_umap_projection_train_10_01, y_train_fer2013)\n",
    "# print(f\"Silhouette Score: {FER_sup_sil_score:.2f}\")\n",
    "# # Calculate Davies-Bouldin Index\n",
    "# FER_sup_db_score = davies_bouldin_score(fer_mean_sup_umap_projection_train_10_01, y_train_fer2013)\n",
    "# print(f\"Davies-Bouldin Index: {FER_sup_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the saved mean UMAP projections\n",
    "mean_projection = np.load('mean_sup_projection_10_01_35.npy')  # Shape: (n_samples, 2)\n",
    "\n",
    "# Step 2: Separate the mean projection by class\n",
    "classes = np.unique(y_train_fer2013)\n",
    "class_gaussians = {}\n",
    "\n",
    "# Calculate the mean and covariance for each class\n",
    "for c in classes:\n",
    "    class_points = mean_projection[y_train_fer2013 == c]  # Filter by class\n",
    "    mean = np.mean(class_points, axis=0)\n",
    "    cov = np.cov(class_points, rowvar=False)\n",
    "    class_gaussians[c] = {\"mean\": mean, \"cov\": cov}\n",
    "\n",
    "# Step 3: Visualize Gaussian distributions\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot UMAP embeddings for each class\n",
    "for c in classes:\n",
    "    class_points = mean_projection[y_train_fer2013 == c]\n",
    "    plt.scatter(class_points[:, 0], class_points[:, 1], label=f\"Class {c}\", alpha=0.5, s=10)\n",
    "\n",
    "    # Plot Gaussian contours\n",
    "    mean = class_gaussians[c][\"mean\"]\n",
    "    cov = class_gaussians[c][\"cov\"]\n",
    "    x, y = np.meshgrid(\n",
    "        np.linspace(mean[0] - 3, mean[0] + 3, 100), \n",
    "        np.linspace(mean[1] - 3, mean[1] + 3, 100)\n",
    "    )\n",
    "    pos = np.dstack((x, y))\n",
    "    rv = multivariate_normal(mean, cov)\n",
    "    plt.contour(x, y, rv.pdf(pos), levels=5, alpha=0.8)\n",
    "\n",
    "plt.title(\"UMAP Mean Projections with Gaussian Distributions per Class\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Evaluate likelihood for a random point\n",
    "random_point = np.array([0, 0])  # Example point in UMAP space\n",
    "likelihoods = {c: multivariate_normal(class_gaussians[c][\"mean\"], class_gaussians[c][\"cov\"]).pdf(random_point)\n",
    "               for c in classes}\n",
    "\n",
    "print(\"Likelihoods for Random Point:\", likelihoods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very low likelihood value (e.g., 1.997e-18 or 2.528e-110) means the random point is far from the mean and not likely to belong to that class.\n",
    "A higher likelihood value (e.g., 7.198e-08) indicates that the point is relatively closer to the Gaussian distribution center for that class.\n",
    "Class 1 (7.198e-08) and Class 5 (1.722e-09) show higher likelihoods compared to the others.\n",
    "This suggests that the random point is closer to the Gaussian centers of these classes.\n",
    "For Classes 3, 4, and 6, the likelihood values are extremely small (e-110, e-29, e-67), meaning the point is far away from those Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihoods = {c: multivariate_normal.logpdf(random_point, mean=class_gaussians[c][\"mean\"], cov=class_gaussians[c][\"cov\"])\n",
    "                   for c in classes}\n",
    "\n",
    "print(\"Log-Likelihoods for Random Point:\", log_likelihoods)\n",
    "# Closer to 0 means higher likelihood.\n",
    "# Larger negative values mean the point is further away from the Gaussian center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised UMAP Standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_unsup_umap_projections_train_10_01= np.load('fer_unsup_umap_projections_train_10_01.npy')\n",
    "fer_mean_unsup_umap_projection_train_10_01= np.load('fer_mean_unsup_umap_projection_train_10_01.npy')\n",
    "fer_std_unsup_umap_projection_train_10_01= np.load('fer_std_unsup_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_unsup_umap_projections_test_10_01= np.load('fer_unsup_umap_projections_test_10_01.npy')\n",
    "fer_mean_unsup_umap_projection_test_10_01= np.load('fer_mean_unsup_umap_projection_test_10_01.npy')\n",
    "fer_std_unsup_umap_projection_test_10_01= np.load('fer_std_unsup_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_unsup_umap_projections_train_10_01 = []\n",
    "fer_unsup_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer2013)\n",
    "    fer_unsup_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer2013)\n",
    "    fer_unsup_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_unsup_umap_projections_train_10_01 = np.array(fer_unsup_umap_projections_train_10_01)\n",
    "fer_unsup_umap_projections_test_10_01 = np.array(fer_unsup_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_unsup_umap_projection_train_10_01 = np.mean(fer_unsup_umap_projections_train_10_01, axis=0)\n",
    "fer_std_unsup_umap_projection_train_10_01 = np.std(fer_unsup_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_unsup_umap_projection_test_10_01 = np.mean(fer_unsup_umap_projections_test_10_01, axis=0)\n",
    "fer_std_unsup_umap_projection_test_10_01 = np.std(fer_unsup_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_unsup_umap_projections_train_10_01.npy', fer_unsup_umap_projections_train_10_01)\n",
    "np.save('fer_mean_unsup_umap_projection_train_10_01.npy', fer_mean_unsup_umap_projection_train_10_01)\n",
    "np.save('fer_std_unsup_umap_projection_train_10_01.npy', fer_std_unsup_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_unsup_umap_projections_test_10_01.npy', fer_unsup_umap_projections_test_10_01)\n",
    "np.save('fer_mean_unsup_umap_projection_test_10_01.npy', fer_mean_unsup_umap_projection_test_10_01)\n",
    "np.save('fer_std_unsup_umap_projection_test_10_01.npy', fer_std_unsup_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_unsup_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_unsup_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Unsupervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_umap_unsup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_umap_projection_test_10_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_fer_umap_unsup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_umap_unsup_10_01 = silhouette_score(fer_mean_unsup_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_umap_unsup_10_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_unsup_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_unsup_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_unsup_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_unsup_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 50\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_unsup_umap_projections_train_50_01 = []\n",
    "fer_unsup_umap_projections_test_50_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer2013)\n",
    "    fer_unsup_umap_projections_train_50_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer2013)\n",
    "    fer_unsup_umap_projections_test_50_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_unsup_umap_projections_train_50_01 = np.array(fer_unsup_umap_projections_train_50_01)\n",
    "fer_unsup_umap_projections_test_50_01 = np.array(fer_unsup_umap_projections_test_50_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_unsup_umap_projection_train_50_01 = np.mean(fer_unsup_umap_projections_train_50_01, axis=0)\n",
    "fer_std_unsup_umap_projection_train_50_01 = np.std(fer_unsup_umap_projections_train_50_01, axis=0)\n",
    "\n",
    "fer_mean_unsup_umap_projection_test_50_01 = np.mean(fer_unsup_umap_projections_test_50_01, axis=0)\n",
    "fer_std_unsup_umap_projection_test_50_01 = np.std(fer_unsup_umap_projections_test_50_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_unsup_umap_projections_train_50_01.npy', fer_unsup_umap_projections_train_50_01)\n",
    "np.save('fer_mean_unsup_umap_projection_train_50_01.npy', fer_mean_unsup_umap_projection_train_50_01)\n",
    "np.save('fer_std_unsup_umap_projection_train_50_01.npy', fer_std_unsup_umap_projection_train_50_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_unsup_umap_projections_test_50_01.npy', fer_unsup_umap_projections_test_50_01)\n",
    "np.save('fer_mean_unsup_umap_projection_test_50_01.npy', fer_mean_unsup_umap_projection_test_50_01)\n",
    "np.save('fer_std_unsup_umap_projection_test_50_01.npy', fer_std_unsup_umap_projection_test_50_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_unsup_umap_projection_train_50_01[:, 0],\n",
    "    fer_mean_unsup_umap_projection_train_50_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"n_neighbours=50 Unsupervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_umap_unsup_50_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_umap_projection_train_50_01, y_train_fer2013).predict(fer_mean_unsup_umap_projection_test_50_01)) # second argument is y_test_pred_pca\n",
    "print(f\"ARI: {ari_fer_umap_unsup_50_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_umap_unsup_50_01 = silhouette_score(fer_mean_unsup_umap_projection_test_50_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_umap_projection_train_50_01, y_train_fer2013).predict(fer_mean_unsup_umap_projection_test_50_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_umap_unsup_50_01:.2f}\")\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_unsup_umap_projection_train_50_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_unsup_umap_projection_50_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_unsup_umap_projection_train_50_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_unsup_umap_projection_50_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Load the saved mean UMAP projections\n",
    "# fer_mean_projection = np.load('fer_mean_unsup_umap_projection_train_10_01.npy')  # Shape: (n_samples, 2)\n",
    "\n",
    "# # Step 2: Separate the mean projection by class\n",
    "# fer_classes = np.unique(y_train_fer2013)\n",
    "# fer_class_gaussians = {}\n",
    "\n",
    "# # Calculate the mean and covariance for each class\n",
    "# for c in fer_classes:\n",
    "#     class_points = fer_mean_projection[y_train_fer2013 == c]  # Filter by class\n",
    "#     mean = np.mean(class_points, axis=0)\n",
    "#     cov = np.cov(class_points, rowvar=False)\n",
    "#     fer_class_gaussians[c] = {\"mean\": mean, \"cov\": cov}\n",
    "\n",
    "# # Step 3: Visualize Gaussian distributions\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# # Plot UMAP embeddings for each class\n",
    "# for c in fer_classes:\n",
    "#     class_points = fer_mean_projection[y_train_fer2013 == c]\n",
    "#     plt.scatter(class_points[:, 0], class_points[:, 1], label=f\"Class {c}\", alpha=0.5, s=10)\n",
    "\n",
    "#     # Plot Gaussian contours\n",
    "#     mean = fer_class_gaussians[c][\"mean\"]\n",
    "#     cov = fer_class_gaussians[c][\"cov\"]\n",
    "#     x, y = np.meshgrid(\n",
    "#         np.linspace(mean[0] - 3, mean[0] + 3, 100), \n",
    "#         np.linspace(mean[1] - 3, mean[1] + 3, 100)\n",
    "#     )\n",
    "#     pos = np.dstack((x, y))\n",
    "#     rv = multivariate_normal(mean, cov)\n",
    "#     plt.contour(x, y, rv.pdf(pos), levels=5, alpha=0.8)\n",
    "\n",
    "# plt.title(\"UMAP Mean Projections with Gaussian Distributions per Class FER2013\")\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Step 4: Evaluate likelihood for a random point\n",
    "# random_point = np.array([0, 0])  # Example point in UMAP space\n",
    "# likelihoods = {c: multivariate_normal(fer_class_gaussians[c][\"mean\"], fer_class_gaussians[c][\"cov\"]).pdf(random_point)\n",
    "#                for c in fer_classes}\n",
    "\n",
    "# print(\"Likelihoods for Random Point:\", likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very low likelihood value (e.g., 1.997e-18 or 2.528e-110) means the random point is far from the mean and not likely to belong to that class.\n",
    "A higher likelihood value (e.g., 7.198e-08) indicates that the point is relatively closer to the Gaussian distribution center for that class.\n",
    "Class 1 (7.198e-08) and Class 5 (1.722e-09) show higher likelihoods compared to the others.\n",
    "This suggests that the random point is closer to the Gaussian centers of these classes.\n",
    "For Classes 3, 4, and 6, the likelihood values are extremely small (e-110, e-29, e-67), meaning the point is far away from those Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihoods = {c: multivariate_normal.logpdf(random_point, mean=class_gaussians[c][\"mean\"], cov=class_gaussians[c][\"cov\"])\n",
    "                   for c in classes}\n",
    "\n",
    "print(\"Log-Likelihoods for Random Point:\", log_likelihoods)\n",
    "# Closer to 0 means higher likelihood.\n",
    "# Larger negative values mean the point is further away from the Gaussian center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply PCA\n",
    "pca = PCA(0.95)\n",
    "x_train_fer2013_pca_emotions = pca.fit_transform(x_train_fer2013)\n",
    "x_test_fer2013_pca_emotions = pca.transform(x_test_fer2013)\n",
    "\n",
    "print(f\"Original number of features: {x_train_fer2013.shape[1]}\")\n",
    "print(f\"Reduced number of features: {x_train_fer2013_pca_emotions.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the projections, mean, and standard deviation\n",
    "np.save('x_train_fer2013_pca_emotions.npy', x_train_fer2013_pca_emotions)\n",
    "np.save('x_test_fer2013_pca_emotions.npy', x_test_fer2013_pca_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + UMAP Unsupervised 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_unsup_pca_umap_projections_train_10_01= np.load('fer_unsup_pca_umap_projections_train_10_01.npy')\n",
    "fer_mean_unsup_pca_umap_projection_train_10_01= np.load('fer_mean_unsup_pca_umap_projection_train_10_01.npy')\n",
    "fer_std_unsup_pca_umap_projection_train_10_01= np.load('fer_std_unsup_pca_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_unsup_pca_umap_projections_test_10_01= np.load('fer_unsup_pca_umap_projections_test_10_01.npy')\n",
    "fer_mean_unsup_pca_umap_projection_test_10_01= np.load('fer_mean_unsup_pca_umap_projection_test_10_01.npy')\n",
    "fer_std_unsup_pca_umap_projection_test_10_01= np.load('fer_std_unsup_pca_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_unsup_pca_umap_projections_train_10_01 = []\n",
    "fer_unsup_pca_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer2013_pca_emotions)\n",
    "    fer_unsup_pca_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer2013_pca_emotions)\n",
    "    fer_unsup_pca_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_unsup_pca_umap_projections_train_10_01 = np.array(fer_unsup_pca_umap_projections_train_10_01)\n",
    "fer_unsup_pca_umap_projections_test_10_01 = np.array(fer_unsup_pca_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_unsup_pca_umap_projection_train_10_01 = np.mean(fer_unsup_pca_umap_projections_train_10_01, axis=0)\n",
    "fer_std_unsup_pca_umap_projection_train_10_01 = np.std(fer_unsup_pca_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_unsup_pca_umap_projection_test_10_01 = np.mean(fer_unsup_pca_umap_projections_test_10_01, axis=0)\n",
    "fer_std_unsup_pca_umap_projection_test_10_01 = np.std(fer_unsup_pca_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_unsup_pca_umap_projections_train_10_01.npy', fer_unsup_pca_umap_projections_train_10_01)\n",
    "np.save('fer_mean_unsup_pca_umap_projection_train_10_01.npy', fer_mean_unsup_pca_umap_projection_train_10_01)\n",
    "np.save('fer_std_unsup_pca_umap_projection_train_10_01.npy', fer_std_unsup_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_unsup_pca_umap_projections_test_10_01.npy', fer_unsup_pca_umap_projections_test_10_01)\n",
    "np.save('fer_mean_unsup_pca_umap_projection_test_10_01.npy', fer_mean_unsup_pca_umap_projection_test_10_01)\n",
    "np.save('fer_std_unsup_pca_umap_projection_test_10_01.npy', fer_std_unsup_pca_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_unsup_pca_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_unsup_pca_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"PCA + Unsupervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_pca_umap_unsup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_pca_umap_projection_test_10_01))\n",
    "print(f\"ARI: {ari_fer_pca_umap_unsup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_pca_umap_unsup_10_01 = silhouette_score(fer_mean_unsup_pca_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_pca_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_pca_umap_unsup_10_01:.2f}\")\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_unsup_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_unsup_pca_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_unsup_pca_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_unsup_pca_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + UMAP Supervised 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_sup_pca_umap_projections_train_10_01= np.load('fer_sup_pca_umap_projections_train_10_01.npy')\n",
    "fer_mean_sup_pca_umap_projection_train_10_01= np.load('fer_mean_sup_pca_umap_projection_train_10_01.npy')\n",
    "fer_std_sup_pca_umap_projection_train_10_01= np.load('fer_std_sup_pca_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_sup_pca_umap_projections_test_10_01= np.load('fer_sup_pca_umap_projections_test_10_01.npy')\n",
    "fer_mean_sup_pca_umap_projection_test_10_01= np.load('fer_mean_sup_pca_umap_projection_test_10_01.npy')\n",
    "fer_std_sup_pca_umap_projection_test_10_01= np.load('fer_std_sup_pca_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_sup_pca_umap_projections_train_10_01 = []\n",
    "fer_sup_pca_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer2013_pca_emotions,y_train_fer2013)\n",
    "    fer_sup_pca_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer2013_pca_emotions)\n",
    "    fer_sup_pca_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_sup_pca_umap_projections_train_10_01 = np.array(fer_sup_pca_umap_projections_train_10_01)\n",
    "fer_sup_pca_umap_projections_test_10_01 = np.array(fer_sup_pca_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_sup_pca_umap_projection_train_10_01 = np.mean(fer_sup_pca_umap_projections_train_10_01, axis=0)\n",
    "fer_std_sup_pca_umap_projection_train_10_01 = np.std(fer_sup_pca_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_sup_pca_umap_projection_test_10_01 = np.mean(fer_sup_pca_umap_projections_test_10_01, axis=0)\n",
    "fer_std_sup_pca_umap_projection_test_10_01 = np.std(fer_sup_pca_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_sup_pca_umap_projections_train_10_01.npy', fer_sup_pca_umap_projections_train_10_01)\n",
    "np.save('fer_mean_sup_pca_umap_projection_train_10_01.npy', fer_mean_sup_pca_umap_projection_train_10_01)\n",
    "np.save('fer_std_sup_pca_umap_projection_train_10_01.npy', fer_std_sup_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_sup_pca_umap_projections_test_10_01.npy', fer_sup_pca_umap_projections_test_10_01)\n",
    "np.save('fer_mean_sup_pca_umap_projection_test_10_01.npy', fer_mean_sup_pca_umap_projection_test_10_01)\n",
    "np.save('fer_std_sup_pca_umap_projection_test_10_01.npy', fer_std_sup_pca_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_sup_pca_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_sup_pca_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"PCA + Supervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_pca_umap_sup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_pca_umap_projection_test_10_01))\n",
    "print(f\"ARI: {ari_fer_pca_umap_sup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_pca_umap_sup_10_01 = silhouette_score(fer_mean_sup_pca_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_pca_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_pca_umap_sup_10_01:.2f}\")\n",
    "\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_sup_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_sup_umap_pca_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_sup_pca_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_sup_umap_pca_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabor + PCA + UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabor + PCA + Unsupervised UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_unsup_gabor_pca_umap_projections_train_10_01= np.load('fer_unsup_gabor_pca_umap_projections_train_10_01.npy')\n",
    "fer_mean_unsup_gabor_pca_umap_projection_train_10_01= np.load('fer_mean_unsup_gabor_pca_umap_projection_train_10_01.npy')\n",
    "fer_std_unsup_gabor_pca_umap_projection_train_10_01= np.load('fer_std_unsup_gabor_pca_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_unsup_gabor_pca_umap_projections_test_10_01= np.load('fer_unsup_gabor_pca_umap_projections_test_10_01.npy')\n",
    "fer_mean_unsup_gabor_pca_umap_projection_test_10_01= np.load('fer_mean_unsup_gabor_pca_umap_projection_test_10_01.npy')\n",
    "fer_std_unsup_gabor_pca_umap_projection_test_10_01= np.load('fer_std_unsup_gabor_pca_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gabor Kernels\n",
    "def create_gabor_kernels():\n",
    "    \"\"\"Generates a set of Gabor kernels with different orientations and frequencies.\"\"\"\n",
    "    kernels = []\n",
    "    ksize = 31  # Kernel size\n",
    "    sigma = 4.0  # Standard deviation of the Gaussian envelope\n",
    "    lambd = 10.0  # Wavelength of the sinusoidal factor\n",
    "    gamma = 0.5  # Spatial aspect ratio\n",
    "    for theta in np.arange(0, np.pi, np.pi / 4):  # 8 orientations\n",
    "        kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi=0, ktype=cv2.CV_32F)\n",
    "        kernels.append(kernel)\n",
    "    return kernels\n",
    "\n",
    "# Apply Gabor Filters\n",
    "def apply_gabor_filters(images, kernels):\n",
    "    \"\"\"Applies a set of Gabor filters to a batch of images.\"\"\"\n",
    "    gabor_features = []\n",
    "    for image in images:\n",
    "        image_2d = image.reshape(48, 48)  # Reshape back to 2D (assumes 48x48 images)\n",
    "        responses = []\n",
    "        for kernel in kernels:\n",
    "            filtered = cv2.filter2D(image_2d, cv2.CV_32F, kernel)  # Apply Gabor filter\n",
    "            responses.append(filtered.flatten())  # Flatten the filtered image\n",
    "        gabor_features.append(np.concatenate(responses))  # Concatenate all filter responses\n",
    "    return np.array(gabor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Gabor kernels\n",
    "gabor_kernels = create_gabor_kernels()\n",
    "print(f\"Generated {len(gabor_kernels)} Gabor kernels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gabor filters to the training and test sets\n",
    "fer_x_train_gabor = apply_gabor_filters(x_train_fer2013, gabor_kernels)\n",
    "fer_x_test_gabor = apply_gabor_filters(x_test_fer2013, gabor_kernels)\n",
    "\n",
    "print(f\"Train Gabor feature shape: {fer_x_train_gabor.shape}\")\n",
    "print(f\"Test Gabor feature shape: {fer_x_test_gabor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "fer_x_train_gabor = scaler.fit_transform(fer_x_train_gabor)\n",
    "fer_x_test_gabor = scaler.transform(fer_x_test_gabor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying PCA to Gabor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "x_fer_train_gabor_pca = pca.fit_transform(fer_x_train_gabor)\n",
    "x_fer_test_gabor_pca = pca.transform(fer_x_test_gabor)\n",
    "\n",
    "print(f\"Reduced train shape: {x_fer_train_gabor_pca.shape}\")\n",
    "print(f\"Reduced test shape: {x_fer_test_gabor_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_raf_train_gabor_pca.npy', x_fer_train_gabor_pca)\n",
    "np.save('x_raf_test_gabor_pca.npy', x_fer_test_gabor_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_unsup_gabor_pca_umap_projections_train_10_01 = []\n",
    "fer_unsup_gabor_pca_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_fer_train_gabor_pca)\n",
    "    fer_unsup_gabor_pca_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_fer_test_gabor_pca)\n",
    "    fer_unsup_gabor_pca_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_unsup_gabor_pca_umap_projections_train_10_01 = np.array(fer_unsup_gabor_pca_umap_projections_train_10_01)\n",
    "fer_unsup_gabor_pca_umap_projections_test_10_01 = np.array(fer_unsup_gabor_pca_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_unsup_gabor_pca_umap_projection_train_10_01 = np.mean(fer_unsup_gabor_pca_umap_projections_train_10_01, axis=0)\n",
    "fer_std_unsup_gabor_pca_umap_projection_train_10_01 = np.std(fer_unsup_gabor_pca_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_unsup_gabor_pca_umap_projection_test_10_01 = np.mean(fer_unsup_gabor_pca_umap_projections_test_10_01, axis=0)\n",
    "fer_std_unsup_gabor_pca_umap_projection_test_10_01 = np.std(fer_unsup_gabor_pca_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_unsup_gabor_pca_umap_projections_train_10_01.npy', fer_unsup_gabor_pca_umap_projections_train_10_01)\n",
    "np.save('fer_mean_unsup_gabor_pca_umap_projection_train_10_01.npy', fer_mean_unsup_gabor_pca_umap_projection_train_10_01)\n",
    "np.save('fer_std_unsup_gabor_pca_umap_projection_train_10_01.npy', fer_std_unsup_gabor_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_unsup_gabor_pca_umap_projections_test_10_01.npy', fer_unsup_gabor_pca_umap_projections_test_10_01)\n",
    "np.save('fer_mean_unsup_gabor_pca_umap_projection_test_10_01.npy', fer_mean_unsup_gabor_pca_umap_projection_test_10_01)\n",
    "np.save('fer_std_unsup_gabor_pca_umap_projection_test_10_01.npy', fer_std_unsup_gabor_pca_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_unsup_gabor_pca_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_unsup_gabor_pca_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Gabor + PCA + Unsupervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_gabor_pca_umap_unsup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_gabor_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_gabor_pca_umap_projection_test_10_01)) # second argument is y_test_fer2013_pred_gabor_pca\n",
    "print(f\"ARI: {ari_fer_gabor_pca_umap_unsup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_gabor_pca_umap_unsup_10_01 = silhouette_score(fer_mean_unsup_gabor_pca_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_gabor_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_unsup_gabor_pca_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_gabor_pca_umap_unsup_10_01:.2f}\")\n",
    "\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_unsup_gabor_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_unsup_gabor_pca_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_unsup_gabor_pca_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_unsup_gabor_pca_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabor + PCA + UMAP Supervised 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the projections, mean, and standard deviation for the training set\n",
    "fer_sup_gabor_pca_umap_projections_train_10_01= np.load('fer_sup_gabor_pca_umap_projections_train_10_01.npy')\n",
    "fer_mean_sup_gabor_pca_umap_projection_train_10_01= np.load('fer_mean_sup_gabor_pca_umap_projection_train_10_01.npy')\n",
    "fer_std_sup_gabor_pca_umap_projection_train_10_01= np.load('fer_std_sup_gabor_pca_umap_projection_train_10_01.npy')\n",
    "\n",
    "# load the projections, mean, and standard deviation for the test set\n",
    "fer_sup_gabor_pca_umap_projections_test_10_01= np.load('fer_sup_gabor_pca_umap_projections_test_10_01.npy')\n",
    "fer_mean_sup_gabor_pca_umap_projection_test_10_01= np.load('fer_mean_sup_gabor_pca_umap_projection_test_10_01.npy')\n",
    "fer_std_sup_gabor_pca_umap_projection_test_10_01= np.load('fer_std_sup_gabor_pca_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for training and test sets\n",
    "fer_sup_gabor_pca_umap_projections_train_10_01 = []\n",
    "fer_sup_gabor_pca_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running Supervised UMAP - Iteration {run + 1}/{n_runs}...\")\n",
    "\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        n_components=n_components, \n",
    "        random_state=run\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data with labels\n",
    "    projection_train = umap_model.fit_transform(x_fer_train_gabor_pca, y_train_fer2013)\n",
    "    fer_sup_gabor_pca_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_fer_test_gabor_pca)\n",
    "    fer_sup_gabor_pca_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_sup_gabor_pca_umap_projections_train_10_01 = np.array(fer_sup_gabor_pca_umap_projections_train_10_01)\n",
    "fer_sup_gabor_pca_umap_projections_test_10_01 = np.array(fer_sup_gabor_pca_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_sup_gabor_pca_umap_projection_train_10_01 = np.mean(fer_sup_gabor_pca_umap_projections_train_10_01, axis=0)\n",
    "fer_std_sup_gabor_pca_umap_projection_train_10_01 = np.std(fer_sup_gabor_pca_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_sup_gabor_pca_umap_projection_test_10_01 = np.mean(fer_sup_gabor_pca_umap_projections_test_10_01, axis=0)\n",
    "fer_std_sup_gabor_pca_umap_projection_test_10_01 = np.std(fer_sup_gabor_pca_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_sup_gabor_pca_umap_projections_train_10_01.npy', fer_sup_gabor_pca_umap_projections_train_10_01)\n",
    "np.save('fer_mean_sup_gabor_pca_umap_projection_train_10_01.npy', fer_mean_sup_gabor_pca_umap_projection_train_10_01)\n",
    "np.save('fer_std_sup_gabor_pca_umap_projection_train_10_01.npy', fer_std_sup_gabor_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_sup_gabor_pca_umap_projections_test_10_01.npy', fer_sup_gabor_pca_umap_projections_test_10_01)\n",
    "np.save('fer_mean_sup_gabor_pca_umap_projection_test_10_01.npy', fer_mean_sup_gabor_pca_umap_projection_test_10_01)\n",
    "np.save('fer_std_sup_gabor_pca_umap_projection_test_10_01.npy', fer_std_sup_gabor_pca_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"Supervised UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer2013)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_sup_gabor_pca_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_sup_gabor_pca_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer2013, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Gabor + PCA + Supervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_gabor_pca_umap_sup_10_01 = adjusted_rand_score(y_test_fer2013, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_gabor_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_gabor_pca_umap_projection_test_10_01)) # second argument is y_test_fer2013_pred_gabor_pca\n",
    "print(f\"ARI: {ari_fer_gabor_pca_umap_sup_10_01:.4f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_gabor_pca_umap_sup_10_01 = silhouette_score(fer_mean_sup_gabor_pca_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_gabor_pca_umap_projection_train_10_01, y_train_fer2013).predict(fer_mean_sup_gabor_pca_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_gabor_pca_umap_sup_10_01:.2f}\")\n",
    "\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_sup_gabor_pca_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_sup_gabor_pca_umap_projection_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_sup_gabor_pca_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_sup_gabor_pca_umap_projection_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLE  Before UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_fer_consistent(x_data, y_labels, sample_fraction=0.75):\n",
    "    \"\"\"\n",
    "    Downsample the dataset consistently, returning indices to ensure\n",
    "    the same points are selected in both spaces.\n",
    "    \n",
    "    Parameters:\n",
    "        x_data (np.array): Input data to downsample.\n",
    "        y_labels (np.array): Corresponding labels.\n",
    "        sample_fraction (float): Fraction of samples to retain per label.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of selected indices.\n",
    "    \"\"\"\n",
    "    sampled_indices = []\n",
    "    unique_labels = np.unique(y_labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Select indices for the current label\n",
    "        label_indices = np.where(y_labels == label)[0]\n",
    "\n",
    "        # Handle cases with very few samples\n",
    "        n_samples = max(1, int(len(label_indices) * sample_fraction))\n",
    "        if n_samples > len(label_indices):\n",
    "            n_samples = len(label_indices)\n",
    "\n",
    "        # Sample a fraction of points for this label\n",
    "        sampled_indices_label = resample(\n",
    "            label_indices, n_samples=n_samples, replace=False, random_state=42\n",
    "        )\n",
    "        sampled_indices.extend(sampled_indices_label)\n",
    "\n",
    "    return np.array(sampled_indices)\n",
    "\n",
    "# Downsample training data\n",
    "fer_sampled_indices_train = downsample_fer_consistent(x_train_fer2013, y_train_fer2013, sample_fraction=0.75)\n",
    "x_train_fer_emotions_sampled = x_train_fer2013[fer_sampled_indices_train]\n",
    "y_train_fer_emotions_sampled = y_train_fer2013[fer_sampled_indices_train]\n",
    "\n",
    "# Downsample test data\n",
    "fer_sampled_indices_test = downsample_fer_consistent(x_test_fer2013, y_test_fer2013, sample_fraction=0.75)\n",
    "x_test_fer_emotions_sampled = x_test_fer2013[fer_sampled_indices_test]\n",
    "y_test_fer_emotions_sampled = y_test_fer2013[fer_sampled_indices_test]\n",
    "\n",
    "# Print results\n",
    "print(f\"Training set reduced to {len(x_train_fer_emotions_sampled)} samples.\")\n",
    "print(f\"Test set reduced to {len(x_test_fer_emotions_sampled)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for LLE\n",
    "n_neighbors = 10\n",
    "n_components = 253 # Same as the reduced from PCA\n",
    "\n",
    "# Initialize the LLE model\n",
    "lle = LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method='standard', random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "print(\"Running LLE on the training set...\")\n",
    "x_train_fer_lle = lle.fit_transform(x_train_fer_emotions_sampled)\n",
    "print(\"LLE transformation on training set completed.\")\n",
    "\n",
    "# Transform the test data using the fitted LLE model\n",
    "print(\"Running LLE on the test set...\")\n",
    "x_test_fer_lle = lle.transform(x_test_fer_emotions_sampled)\n",
    "print(\"LLE transformation on test set completed.\")\n",
    "\n",
    "# Print shapes of transformed data\n",
    "print(f\"Shape of LLE-transformed training data: {x_train_fer_lle.shape}\")\n",
    "print(f\"Shape of LLE-transformed test data: {x_test_fer_lle.shape}\")\n",
    "\n",
    "# Optional: Save the LLE-transformed data for later use\n",
    "np.save('x_train_lle.npy', x_train_fer_lle)\n",
    "np.save('x_test_lle.npy', x_test_fer_lle)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"LLE-transformed data has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLE + UMAP Unsupervised 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the projections, mean, and standard deviation for the training set\n",
    "fer_unsup_lle_umap_projections_train_10_01= np.load('fer_unsup_lle_umap_projections_train_10_01.npy')\n",
    "fer_mean_unsup_lle_umap_projection_train_10_01= np.load('fer_mean_unsup_lle_umap_projection_train_10_01.npy')\n",
    "fer_std_unsup_lle_umap_projection_train_10_01= np.load('fer_std_unsup_lle_umap_projection_train_10_01.npy')\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "fer_unsup_lle_umap_projections_test_10_01= np.load('fer_unsup_lle_umap_projections_test_10_01.npy')\n",
    "fer_mean_unsup_lle_umap_projection_test_10_01= np.load('fer_mean_unsup_lle_umap_projection_test_10_01.npy')\n",
    "fer_std_unsup_lle_umap_projection_test_10_01= np.load('fer_std_unsup_lle_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_unsup_lle_umap_projections_train_10_01 = []\n",
    "fer_unsup_lle_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer_lle)\n",
    "    fer_unsup_lle_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer_lle)\n",
    "    fer_unsup_lle_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_unsup_lle_umap_projections_train_10_01 = np.array(fer_unsup_lle_umap_projections_train_10_01)\n",
    "fer_unsup_lle_umap_projections_test_10_01 = np.array(fer_unsup_lle_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_unsup_lle_umap_projection_train_10_01 = np.mean(fer_unsup_lle_umap_projections_train_10_01, axis=0)\n",
    "fer_std_unsup_lle_umap_projection_train_10_01 = np.std(fer_unsup_lle_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_unsup_lle_umap_projection_test_10_01 = np.mean(fer_unsup_lle_umap_projections_test_10_01, axis=0)\n",
    "fer_std_unsup_lle_umap_projection_test_10_01 = np.std(fer_unsup_lle_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_unsup_lle_umap_projections_train_10_01.npy', fer_unsup_lle_umap_projections_train_10_01)\n",
    "np.save('fer_mean_unsup_lle_umap_projection_train_10_01.npy', fer_mean_unsup_lle_umap_projection_train_10_01)\n",
    "np.save('fer_std_unsup_lle_umap_projection_train_10_01.npy', fer_std_unsup_lle_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_unsup_lle_umap_projections_test_10_01.npy', fer_unsup_lle_umap_projections_test_10_01)\n",
    "np.save('fer_mean_unsup_lle_umap_projection_test_10_01.npy', fer_mean_unsup_lle_umap_projection_test_10_01)\n",
    "np.save('fer_std_unsup_lle_umap_projection_test_10_01.npy', fer_std_unsup_lle_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer_emotions_sampled)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_unsup_lle_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_unsup_lle_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer_emotions_sampled, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"LLE + Unsupervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_lle_umap_unsup_10_01 = adjusted_rand_score(y_test_fer_emotions_sampled, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_lle_umap_projection_train_10_01, y_train_fer_emotions_sampled).predict(fer_mean_unsup_lle_umap_projection_test_10_01)) # second argument is y_test_pred_lle\n",
    "print(f\"ARI: {ari_fer_lle_umap_unsup_10_01:.2f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_lle_umap_unsup_10_01 = silhouette_score(fer_mean_unsup_lle_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_unsup_lle_umap_projection_train_10_01, y_train_fer_emotions_sampled).predict(fer_mean_unsup_lle_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_lle_umap_unsup_10_01:.2f}\")\n",
    "\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_unsup_lle_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_lle_umap_unsup_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_unsup_lle_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_lle_umap_unsup_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLE + UMAP Supervised 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the projections, mean, and standard deviation for the training set\n",
    "fer_sup_lle_umap_projections_train_10_01= np.load('fer_sup_lle_umap_projections_train_10_01.npy')\n",
    "fer_mean_sup_lle_umap_projection_train_10_01= np.load('fer_mean_sup_lle_umap_projection_train_10_01.npy')\n",
    "fer_std_sup_lle_umap_projection_train_10_01= np.load('fer_std_sup_lle_umap_projection_train_10_01.npy')\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "fer_sup_lle_umap_projections_test_10_01= np.load('fer_sup_lle_umap_projections_test_10_01.npy')\n",
    "fer_mean_sup_lle_umap_projection_test_10_01= np.load('fer_mean_sup_lle_umap_projection_test_10_01.npy')\n",
    "fer_std_sup_lle_umap_projection_test_10_01= np.load('fer_std_sup_lle_umap_projection_test_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run (train and test)\n",
    "fer_sup_lle_umap_projections_train_10_01 = []\n",
    "fer_sup_lle_umap_projections_test_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times for the training set\n",
    "for run in range(n_runs):\n",
    "    print(f\"Running UMAP on Training Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, random_state=run)\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    projection_train = umap_model.fit_transform(x_train_fer_lle, y_train_fer_emotions_sampled)\n",
    "    fer_sup_lle_umap_projections_train_10_01.append(projection_train)\n",
    "    \n",
    "    # Transform the test data using the same fitted model\n",
    "    print(f\"Running UMAP on Test Set - Iteration {run + 1}/{n_runs}...\")\n",
    "    projection_test = umap_model.transform(x_test_fer_lle)\n",
    "    fer_sup_lle_umap_projections_test_10_01.append(projection_test)\n",
    "\n",
    "# Convert the list of projections to numpy arrays\n",
    "fer_sup_lle_umap_projections_train_10_01 = np.array(fer_sup_lle_umap_projections_train_10_01)\n",
    "fer_sup_lle_umap_projections_test_10_01 = np.array(fer_sup_lle_umap_projections_test_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs (train and test)\n",
    "fer_mean_sup_lle_umap_projection_train_10_01 = np.mean(fer_sup_lle_umap_projections_train_10_01, axis=0)\n",
    "fer_std_sup_lle_umap_projection_train_10_01 = np.std(fer_sup_lle_umap_projections_train_10_01, axis=0)\n",
    "\n",
    "fer_mean_sup_lle_umap_projection_test_10_01 = np.mean(fer_sup_lle_umap_projections_test_10_01, axis=0)\n",
    "fer_std_sup_lle_umap_projection_test_10_01 = np.std(fer_sup_lle_umap_projections_test_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the training set\n",
    "np.save('fer_sup_lle_umap_projections_train_10_01.npy', fer_sup_lle_umap_projections_train_10_01)\n",
    "np.save('fer_mean_sup_lle_umap_projection_train_10_01.npy', fer_mean_sup_lle_umap_projection_train_10_01)\n",
    "np.save('fer_std_sup_lle_umap_projection_train_10_01.npy', fer_std_sup_lle_umap_projection_train_10_01)\n",
    "\n",
    "# Save the projections, mean, and standard deviation for the test set\n",
    "np.save('fer_sup_lle_umap_projections_test_10_01.npy', fer_sup_lle_umap_projections_test_10_01)\n",
    "np.save('fer_mean_sup_lle_umap_projection_test_10_01.npy', fer_mean_sup_lle_umap_projection_test_10_01)\n",
    "np.save('fer_std_sup_lle_umap_projection_test_10_01.npy', fer_std_sup_lle_umap_projection_test_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections for training and test sets, mean, and standard deviations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust colormap to have exactly 7 colors\n",
    "unique_labels = np.unique(y_train_fer_emotions_sampled)\n",
    "cmap = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(\n",
    "    fer_mean_sup_lle_umap_projection_train_10_01[:, 0],\n",
    "    fer_mean_sup_lle_umap_projection_train_10_01[:, 1],\n",
    "    c=y_train_fer_emotions_sampled, cmap=cmap, s=5, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"LLE + Supervised UMAP Projection of FER2013 Training Data (10 Runs)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "\n",
    "# Add and configure the colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(0, 7))  # Ensure ticks align with labels\n",
    "cbar.set_ticklabels([f\"Emotion {label}\" for label in range(0, 7)])  # Customize labels\n",
    "cbar.set_label(\"Emotion Labels\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI\n",
    "ari_fer_lle_umap_sup_10_01 = adjusted_rand_score(y_test_fer_emotions_sampled, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_lle_umap_projection_train_10_01, y_train_fer_emotions_sampled).predict(fer_mean_sup_lle_umap_projection_test_10_01)) # second argument is y_test_pred_lle\n",
    "print(f\"ARI: {ari_fer_lle_umap_sup_10_01:.2f}\")\n",
    "# Silhouette Score\n",
    "silhouette_fer_lle_umap_sup_10_01 = silhouette_score(fer_mean_sup_lle_umap_projection_test_10_01, KNeighborsClassifier(n_neighbors=1).fit(fer_mean_sup_lle_umap_projection_train_10_01, y_train_fer_emotions_sampled).predict(fer_mean_sup_lle_umap_projection_test_10_01))\n",
    "print(f\"Silhouette Score: {silhouette_fer_lle_umap_sup_10_01:.2f}\")\n",
    "\n",
    "# Use KMeans for clustering\n",
    "n_clusters = len(np.unique(y_train_fer2013))  # Number of clusters = number of unique labels\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans on the training set UMAP projections\n",
    "predicted_labels = kmeans.fit_predict(fer_mean_sup_lle_umap_projection_train_10_01)\n",
    "\n",
    "# Compute Davies-Bouldin Index\n",
    "fer_lle_umap_sup_10_01_db_score = davies_bouldin_score(\n",
    "    fer_mean_sup_lle_umap_projection_train_10_01,  # Training set mean projections\n",
    "    predicted_labels  # Labels from KMeans clustering\n",
    ")\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {fer_lle_umap_sup_10_01_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAF_FER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply PCA to reduce dimensionality\n",
    "pca = PCA(0.95)\n",
    "x_train_fer2013_pca = pca.fit_transform(x_train_fer2013_scaled)  # x_train is the normalized flattened pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "n_neighbors = 10\n",
    "min_dist = 0.1\n",
    "n_components = 2\n",
    "n_runs = 10  # Number of runs\n",
    "\n",
    "# Store UMAP projections for each run\n",
    "RAF_FER_pca_unsup_umap_projections_10_01 = []\n",
    "\n",
    "# Run UMAP multiple times\n",
    "for run in range(n_runs):\n",
    "    # Create UMAP model\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components,random_state=None)\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    RAF_FER_pca_umap_projection = umap_model.fit_transform(x_train_fer2013_pca)\n",
    "    \n",
    "    # Store the projection\n",
    "    RAF_FER_pca_unsup_umap_projections_10_01.append(RAF_FER_pca_umap_projection)\n",
    "\n",
    "# Convert the list of projections to a numpy array\n",
    "RAF_FER_pca_unsup_umap_projections_10_01 = np.array(RAF_FER_pca_unsup_umap_projections_10_01)\n",
    "\n",
    "# Calculate mean and standard deviation of projections across runs\n",
    "RAF_FER_mean_pca_unsup_umap_projections_10_01 = np.mean(RAF_FER_pca_unsup_umap_projections_10_01, axis=0)\n",
    "RAF_FER_std_pca_unsup_umap_projections_10_01 = np.std(RAF_FER_pca_unsup_umap_projections_10_01, axis=0)\n",
    "\n",
    "# Save the projections, mean, and standard deviation\n",
    "np.save('RAF_FER_pca_unsup_umap_projections_10_01.npy', RAF_FER_pca_unsup_umap_projections_10_01)\n",
    "np.save('RAF_FER_mean_pca_unsup_umap_projections_10_01.npy', RAF_FER_mean_pca_unsup_umap_projections_10_01)\n",
    "np.save('RAF_FER_std_pca_unsup_umap_projections_10_01.npy', RAF_FER_std_pca_unsup_umap_projections_10_01)\n",
    "\n",
    "# Output confirmation\n",
    "print(\"UMAP projections, mean, and standard deviation have been saved with identifiers '_10_01'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAF_FER_pca_unsup_umap_projections_10_01= np.load(f'RAF_FER_pca_unsup_umap_projections_10_01.npy')\n",
    "RAF_FER_mean_pca_unsup_umap_projections_10_01= np.load(f'RAF_FER_mean_pca_unsup_umap_projections_10_01.npy')\n",
    "RAF_FER_std_pca_unsup_umap_projections_10_01= np.load(f'RAF_FER_std_pca_unsup_umap_projections_10_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the UMAP results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(RAF_FER_mean_pca_unsup_umap_projections_10_01[:, 0], RAF_FER_mean_pca_unsup_umap_projections_10_01[:, 1], c=y_train_fer2013, cmap=\"coolwarm\", s=5, alpha=0.8)\n",
    "plt.title(\"Unsup. PCA UMAP Projection: Dataset Identification FER2013\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"FER2013 Emotions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette Score\n",
    "FER_pca_unsup_umap_sil_score = silhouette_score(RAF_FER_mean_pca_unsup_umap_projections_10_01, y_train_fer2013)\n",
    "print(f\"Silhouette Score: {FER_pca_unsup_umap_sil_score:.2f}\")\n",
    "# Calculate Davies-Bouldin Index\n",
    "FER_pca_unsup_db_score = davies_bouldin_score(RAF_FER_mean_pca_unsup_umap_projections_10_01, y_train_fer2013)\n",
    "print(f\"Davies-Bouldin Index: {FER_pca_unsup_db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT RUN YET ##\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Fit Gaussian distributions to each class\n",
    "unique_labels = np.unique(y_train)\n",
    "gaussian_params = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    class_points = gabor_predicted_labels[y_train == label]\n",
    "    mean = np.mean(class_points, axis=0)\n",
    "    cov = np.cov(class_points, rowvar=False)\n",
    "    gaussian_params[label] = multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "# Example: Compare likelihoods of a random point belonging to each class\n",
    "sample_point = gabor_predicted_labels[0]  # Random point\n",
    "likelihoods = {label: dist.pdf(sample_point) for label, dist in gaussian_params.items()}\n",
    "print(\"Likelihoods for Random Point:\", likelihoods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply UMAP to PCA-reduced data\n",
    "reducer_pca = umap.UMAP(n_neighbors=50, min_dist=0.0, n_components=2, random_state=42)\n",
    "x_train_umap_pca = reducer_pca.fit_transform(x_train_pca)\n",
    "pca_mean_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_train_umap_pca[:, 0],\n",
    "    x_train_umap_pca[:, 1],\n",
    "    c=y_train,  # 0 for FER2013, 1 for RAF\n",
    "    cmap=\"coolwarm\",\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title(\"PCA + UMAP Projection: Dataset Identification (RAF vs FER2013)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Dataset (0=FER2013, 1=RAF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette score\n",
    "sil_score_pca = silhouette_score(x_train_umap_pca, y_train)\n",
    "print(\"Silhouette Score:\", sil_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET50 + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Data for ResNet50\n",
    "x_train_resized = np.repeat(x_train.reshape(-1, 48, 48, 1), 3, axis=-1)  # Convert grayscale to RGB\n",
    "x_test_resized = np.repeat(x_test.reshape(-1, 48, 48, 1), 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract Features Using ResNet50\n",
    "resnet = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Preprocess images\n",
    "x_train_preprocessed = preprocess_input(x_train_resized)\n",
    "x_test_preprocessed = preprocess_input(x_test_resized)\n",
    "\n",
    "# Predict and extract features\n",
    "train_features = resnet.predict(x_train_preprocessed, verbose=1)\n",
    "test_features = resnet.predict(x_test_preprocessed, verbose=1)\n",
    "\n",
    "# Flatten the extracted features\n",
    "x_train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "x_test_features = test_features.reshape(test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply UMAP to ResNet Features\n",
    "reducer3 = umap.UMAP(n_neighbors=50, min_dist=0.0, n_components=2, random_state=42)\n",
    "x_train_umap3 = reducer3.fit_transform(x_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize the Results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_train_umap3[:, 0],\n",
    "    x_train_umap3[:, 1],\n",
    "    c=y_train,  # 0 for FER2013, 1 for RAF\n",
    "    cmap=\"coolwarm\",\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title(\"ResNet50 Features + UMAP: Dataset Identification (RAF vs FER2013)\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Dataset (0=FER2013, 1=RAF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette score\n",
    "sil_score_resnet = silhouette_score(x_train_umap3, y_train)\n",
    "print(\"Silhouette Score:\", sil_score_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARI METRIC\n",
    "# Step 2: Cluster the UMAP-reduced data using KMeans\n",
    "n_clusters = len(np.unique(y_train))  # Number of unique labels in y_train\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(x_train_umap3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute Adjusted Rand Index (ARI)\n",
    "ari_score = adjusted_rand_score(y_train, kmeans_labels)  # y_train: ground truth labels\n",
    "print(\"Adjusted Rand Index (ARI):\", ari_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize Clustering Results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_train_umap[:, 0],\n",
    "    x_train_umap[:, 1],\n",
    "    c=kmeans_labels,  # Color by KMeans clusters\n",
    "    cmap=\"tab10\",\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title(\"UMAP + KMeans Clustering\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Cluster Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISOMAP + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Downsample the Dataset Consistently\n",
    "def downsample_consistent(x_train, y_train, sample_fraction=0.35):\n",
    "    \"\"\"\n",
    "    Downsample the dataset consistently, ensuring label distribution is preserved.\n",
    "    Returns sampled indices to extract data points and labels.\n",
    "    \"\"\"\n",
    "    sampled_indices = []\n",
    "    unique_labels = np.unique(y_train)\n",
    "    for label in unique_labels:\n",
    "        # Get indices for the current label\n",
    "        label_indices = np.where(y_train == label)[0]\n",
    "        # Sample a fraction of points for this label\n",
    "        sampled_indices_label = resample(\n",
    "            label_indices, n_samples=int(len(label_indices) * sample_fraction), replace=False\n",
    "        )\n",
    "        sampled_indices.extend(sampled_indices_label)\n",
    "    return np.array(sampled_indices)\n",
    "\n",
    "# Downsample x_train and y_train\n",
    "sample_fraction = 0.35\n",
    "sampled_indices = downsample_consistent(x_train, y_train, sample_fraction=sample_fraction)\n",
    "\n",
    "# Extract downsampled data\n",
    "x_train_sampled = x_train[sampled_indices]\n",
    "y_train_sampled = y_train[sampled_indices]\n",
    "\n",
    "print(\"Downsampled x_train shape:\", x_train_sampled.shape)\n",
    "print(\"Downsampled y_train shape:\", y_train_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Normalize the Sampled Data\n",
    "scaler = StandardScaler()\n",
    "x_train_sampled_scaled = scaler.fit_transform(x_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply Isomap for Dimensionality Reduction\n",
    "n_neighbors_isomap = 10  # Number of neighbors for Isomap\n",
    "n_components_isomap = 50  # Reduce to 50 dimensions before UMAP\n",
    "isomap = Isomap(n_neighbors=n_neighbors_isomap, n_components=n_components_isomap)\n",
    "x_train_isomap = isomap.fit_transform(x_train_sampled_scaled)\n",
    "\n",
    "print(\"Isomap reduced shape:\", x_train_isomap.shape)\n",
    "\n",
    "# Step 4: Apply UMAP for Further Reduction to 2D\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "x_train_umap = reducer.fit_transform(x_train_isomap)\n",
    "\n",
    "# Step 5: Visualize the Results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    x_train_umap[:, 0],\n",
    "    x_train_umap[:, 1],\n",
    "    c=y_train_sampled,  # Color by ground truth labels\n",
    "    cmap=\"tab10\",\n",
    "    s=5,\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title(\"Isomap + UMAP Projection: Downsampled Training Data\")\n",
    "plt.xlabel(\"UMAP Component 1\")\n",
    "plt.ylabel(\"UMAP Component 2\")\n",
    "plt.colorbar(label=\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sampled indices\n",
    "np.save(\"sampled_indices.npy\", sampled_indices)\n",
    "\n",
    "# Save the downsampled dataset\n",
    "np.save(\"x_sampled.npy\", x_sampled)\n",
    "np.save(\"y_sampled.npy\", y_sampled)\n",
    "\n",
    "print(\"Downsampling saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Isomap to the subset of data\n",
    "isomap = Isomap(n_components=50, n_neighbors=5)  # Reduced n_neighbors to 5 for faster computation\n",
    "# x_train_isomap_subset = isomap.fit_transform(x_train_subset)\n",
    "x_reduced = isomap.fit_transform(x_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Isomap-reduced data\n",
    "# np.save(\"isomap_embedding_subsets.npy\", x_train_isomap_subset)\n",
    "np.save(\"isomap_embedding_subsets_evenly_downsampled.npy\", x_reduced)\n",
    "print(\"Isomap embeddings saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
